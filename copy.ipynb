{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eaa3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62b820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bace3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_modified(regularizer_rate_0,regularizer_rate_1,num_layers_0, epochs, batch_size, num_classes, sensor_sizes, dep, xvals, yvals, reduction):\n",
    "\n",
    "  from numpy.linalg import norm\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import tensorflow as tf\n",
    "  from sklearn.metrics import accuracy_score\n",
    "  from tensorflow.keras.layers import Dense, Activation\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.disable_v2_behavior()\n",
    "  from sklearn.model_selection import train_test_split\n",
    "\n",
    "  xvals_train, xvals_test,yvals_train, yvals_test = train_test_split(xvals,yvals,random_state=None, test_size=0.2,  shuffle=True)\n",
    "                                                                     \n",
    "  starter_learning_rate = 0.001\n",
    "  num_features=sum(sensor_sizes)\n",
    "  nrow=len(yvals_train)\n",
    "  num_output=num_classes\n",
    "\n",
    "  input_X = tf.placeholder('float32',shape =(None,num_features),name=\"input_X\")\n",
    "  input_y = tf.placeholder('float32',shape = (None,num_classes),name='input_Y')\n",
    "\n",
    "  s=tf.compat.v1.InteractiveSession()\n",
    "  ## Weights initialized by random normal function with std_dev = 1/sqrt(number of input features)\n",
    "  weights_0 = tf.Variable(tf.random.normal([num_features,num_layers_0], stddev=(1/tf.sqrt(float(num_features)))))\n",
    "  bias_0 = tf.Variable(tf.random.normal([num_layers_0]))\n",
    "  weights_1 = tf.Variable(tf.random.normal([num_layers_0,num_output], stddev=(1/tf.sqrt(float(num_layers_0)))))\n",
    "  bias_1 = tf.Variable(tf.random.normal([num_output]))\n",
    "\n",
    "  ## Initializing weigths and biases\n",
    "  hidden_output_0 = tf.nn.relu(tf.matmul(input_X,weights_0)+bias_0)\n",
    "  predicted_y = tf.sigmoid(tf.matmul(hidden_output_0,weights_1) + bias_1)\n",
    "\n",
    "  ##calculate penalty terms\n",
    "  series = pd.Series(sensor_sizes)\n",
    "  cumsum = series.cumsum()\n",
    "  penalty=(tf.reduce_sum(tf.square(weights_0[0:sensor_sizes[0]])))**0.5/sensor_sizes[0]\n",
    "  for i in range(len(sensor_sizes)-1):\n",
    "    penalty=penalty+((tf.reduce_sum(tf.square(weights_0[cumsum[i]:cumsum[i+1]])))**0.5)/sensor_sizes[i+1]\n",
    "\n",
    "  cumsum =[0]+ list(series.cumsum())\n",
    "  redund=0\n",
    "  r_mat=np.array(xvals_train.corr())\n",
    "  rsq_mat=[[elem*elem for elem in inner] for inner in r_mat]\n",
    "  rsq_mat=pd.DataFrame(rsq_mat)\n",
    "  for i in range(len(sensor_sizes)):\n",
    "    for j in range(len(sensor_sizes)):\n",
    "      if j!=i:\n",
    "        redund=redund+dep(rsq_mat,sensor_sizes,i+1,j+1)*((tf.reduce_sum(tf.square(weights_0[cumsum[j]:cumsum[j+1]])))*(tf.reduce_sum(tf.square(weights_0[cumsum[i]:cumsum[i+1]])))**0.5)/(sensor_sizes[i]*sensor_sizes[j])\n",
    "\n",
    "  if len(sensor_sizes)>1:\n",
    "    redund=redund/(len(sensor_sizes)*(len(sensor_sizes)-1))\n",
    "\n",
    "  loss = tf.reduce_mean(tf.square(predicted_y-tf.convert_to_tensor(yvals_train, dtype=tf.float32))) + regularizer_rate_0*redund/num_layers_0**2 + regularizer_rate_1*penalty/num_layers_0 \n",
    "\n",
    "\n",
    "  ## Variable learning rate\n",
    "  learning_rate = tf.train.exponential_decay(starter_learning_rate, 0, 5, 0.85, staircase=True)\n",
    "  ## Adam optimzer for finding the right weight\n",
    "  optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,var_list=[weights_0,weights_1,\n",
    "                                                                         bias_0,bias_1])    \n",
    "  ## Metrics definition\n",
    "  correct_prediction = tf.equal(tf.argmax(yvals_train,1), tf.argmax(predicted_y,1))\n",
    "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  training_accuracy = []\n",
    "  training_loss = []\n",
    "\n",
    "  #s.run(tf.initialize_all_variables)\n",
    "  s.run(tf.compat.v1.global_variables_initializer())\n",
    "  for epoch in range(epochs):    \n",
    "    arr = np.arange(nrow)\n",
    "    np.random.shuffle(arr)\n",
    "    for index in range(0,nrow,batch_size):\n",
    "        s.run(optimizer, {input_X: xvals_train,\n",
    "                          input_y: yvals_train})\n",
    "        \n",
    "    training_accuracy.append(s.run(accuracy, feed_dict= {input_X:xvals_train, \n",
    "                                                         input_y: yvals_train}))\n",
    "    training_loss.append(s.run(loss, {input_X: xvals_train, \n",
    "                                      input_y: yvals_train}))\n",
    "    \n",
    "  \n",
    "  y_pred = np.rint(s.run(predicted_y, feed_dict={input_X: xvals_test}))\n",
    "\n",
    "  testacc = accuracy_score(yvals_test, y_pred)\n",
    " \n",
    "  print(\"\\nTest Accuracy: {0:f}\\n\".format(testacc))\n",
    "\n",
    "  w0=weights_0.eval()\n",
    "  w=[]\n",
    "  #w.append(norm(w0[0:sensor_sizes[0]],2))\n",
    "  for i in range(len(sensor_sizes)):\n",
    "    w.append(norm(w0[cumsum[i]:cumsum[i+1]],2))\n",
    "  print(w)\n",
    "  #Feature selection\n",
    "  if reduction==True:\n",
    "    v=[i for i,x in enumerate(w) if x > 0.1*max(w)]\n",
    "    selected=[]\n",
    "    for i in v:\n",
    "      selected.append(xvals.iloc[:,range(cumsum[i],cumsum[i+1])])\n",
    "    \n",
    "    xvals_reduced=pd.concat(selected,ignore_index=True, axis=1)\n",
    "    \n",
    "    acc=0\n",
    "    sensor_sizes_red=[sensor_sizes[i] for i in v]\n",
    "    for i in range(10):\n",
    "     x=func_modified(regularizer_rate_0,regularizer_rate_1,num_layers_0, epochs, batch_size, num_classes, sensor_sizes_red,dep_cor,xvals_reduced,yvals,reduction=False)\n",
    "     acc=acc+x[0]\n",
    "    s.close()\n",
    "    return([acc/10,len(sensor_sizes_red),v])\n",
    "  else:\n",
    "    s.close()\n",
    "    return([testacc,len(sensor_sizes)])\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "#function for dependency between m th and n th sensor\n",
    "\n",
    "def dep_cor(rsq_mat,sensor,m,n):\n",
    "  \n",
    "  series = pd.Series(sensor)\n",
    "  cumsum = list(series.cumsum())\n",
    "  cumsum=[0]+cumsum\n",
    "  ind1=list(range(cumsum[m-1],cumsum[m]))\n",
    "  ind2=list(range(cumsum[n-1],cumsum[n]))\n",
    "  cor=rsq_mat.iloc[ind1,ind2]\n",
    "  return(min(cor.apply(max,1)))\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "#RSData-1\n",
    "\n",
    "#rs=pd.read_csv('/Users/aytijhyasaha/Documents/datasets/sensor-selection-datasets/rs_8cl.csv')\n",
    "rs=pd.read_csv('C:/Users/CILAB2/Downloads/ayti-datasets/rs_8cl.csv')\n",
    "xvals = rs.iloc[:,1:8]\n",
    "yvals = rs.iloc[:,8]\n",
    "yvals=to_categorical(np.asarray(yvals.factorize()[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca67856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\CILAB2\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "\n",
      "Test Accuracy: 0.000000\n",
      "\n",
      "[2.4752614, 2.2155418, 1.8321528, 2.4455934, 2.1298623, 1.7064627, 1.529454]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CILAB2\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.045852\n",
      "\n",
      "[1.2201331, 2.257128, 2.6282852, 2.5738451, 1.7471452, 1.7423271, 1.8941672]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CILAB2\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-29441fa02d28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc_modified\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdep_cor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxvals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myvals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mresult_rsdata2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-1760b60a98ec>\u001b[0m in \u001b[0;36mfunc_modified\u001b[1;34m(regularizer_rate_0, regularizer_rate_1, num_layers_0, epochs, batch_size, num_classes, sensor_sizes, dep, xvals, yvals, reduction)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[0msensor_sizes_red\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msensor_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m      \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc_modified\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregularizer_rate_0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mregularizer_rate_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_layers_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msensor_sizes_red\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdep_cor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxvals_reduced\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myvals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m      \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-1760b60a98ec>\u001b[0m in \u001b[0;36mfunc_modified\u001b[1;34m(regularizer_rate_0, regularizer_rate_1, num_layers_0, epochs, batch_size, num_classes, sensor_sizes, dep, xvals, yvals, reduction)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         s.run(optimizer, {input_X: xvals_train,\n\u001b[0m\u001b[0;32m     75\u001b[0m                           input_y: yvals_train})\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    959\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1181\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1182\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1358\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1359\u001b[0m                            run_metadata)\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1350\u001b[0m                                       target_list, run_metadata)\n\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1439\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1440\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1441\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m                                             run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for i in [0,2,5]:\n",
    "  for j in [0,2,5]:\n",
    "    x=func_modified(i,j,20,400,100,8,[1,1,1,1,1,1,1],dep_cor,xvals,yvals,True)\n",
    "    result.append([i,j,x[0],x[1],x[2]])\n",
    "    result_rsdata2=pd.DataFrame(result)\n",
    "    result_rsdata2.columns =[\"Lambda\",\"Mu\", \"Test Accuracy\", \"Number of sensors selected\",\"Selected sensors\"]\n",
    "    writer = pd.ExcelWriter('output_1_rsdata2.xlsx')\n",
    "    result_rsdata2.to_excel(writer)\n",
    "    writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e74fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
