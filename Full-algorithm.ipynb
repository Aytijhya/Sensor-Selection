{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53815,"status":"ok","timestamp":1675774519930,"user":{"displayName":"Aytijhya Saha","userId":"15087240692289809888"},"user_tz":-330},"id":"_sAmtJcZIanm","outputId":"bb1deddd-7fc9-442d-cd49-532676cc8a0c"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","from numpy.linalg import norm\n","import keras\n","from keras.layers import Activation, Dense\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","from tensorflow.keras.layers import Dense, Activation\n","from tensorflow.keras.utils import to_categorical\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b0finWVHImKO"},"outputs":[],"source":["import numpy as np\n","import scipy.io\n","\n","m = scipy.io.loadmat('/content/drive/MyDrive/datasets/BCICIV_1_mat/BCICIV_calib_ds1d.mat', struct_as_record=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QdY8lfR_JHlL"},"outputs":[],"source":["iris=pd.read_csv('/content/drive/MyDrive/Iris.csv')\n","xvals = iris[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].astype(np.float32)\n","yvals = iris['Species']\n","yvals=to_categorical(np.asarray(yvals.factorize()[0]))"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"ZkJqdSwDxuGK","executionInfo":{"status":"ok","timestamp":1675794541513,"user_tz":-330,"elapsed":521,"user":{"displayName":"Aytijhya Saha","userId":"15087240692289809888"}}},"outputs":[],"source":["def func_modified(regularizer_rate_0,regularizer_rate_1,num_layers_0, epochs, batch_size, num_classes, sensor_sizes, dep):\n","\n","  from numpy.linalg import norm\n","  import keras\n","  from keras.layers import Activation, Dense\n","  import numpy as np\n","  import pandas as pd\n","  import seaborn as sns\n","  import matplotlib.pyplot as plt\n","  import tensorflow as tf\n","  from sklearn.metrics import roc_auc_score, accuracy_score, precision_score\n","  from tensorflow.keras.layers import Dense, Activation\n","  from tensorflow.keras.utils import to_categorical\n","  import tensorflow.compat.v1 as tf\n","  tf.disable_v2_behavior()\n","  from sklearn.model_selection import train_test_split\n","  \n","\n","  xvals_train, xvals_test,yvals_train, yvals_test = train_test_split(xvals,yvals,\n","                                   random_state=104, \n","                                   test_size=0.2, \n","                                   shuffle=True)\n","  \n","\n","  starter_learning_rate = 0.001\n","  num_features=sum(sensor_sizes)\n","  nrow=len(yvals_train)\n","  num_output=num_classes\n","\n","  input_X = tf.placeholder('float32',shape =(None,num_features),name=\"input_X\")\n","  input_y = tf.placeholder('float32',shape = (None,num_classes),name='input_Y')\n","\n","  s=tf.compat.v1.InteractiveSession()\n","  ## Weights initialized by random normal function with std_dev = 1/sqrt(number of input features)\n","  weights_0 = tf.Variable(tf.random.normal([num_features,num_layers_0], stddev=(1/tf.sqrt(float(num_features)))))\n","  bias_0 = tf.Variable(tf.random.normal([num_layers_0]))\n","  weights_1 = tf.Variable(tf.random.normal([num_layers_0,num_output], stddev=(1/tf.sqrt(float(num_layers_0)))))\n","  bias_1 = tf.Variable(tf.random.normal([num_output]))\n","\n","  ## Initializing weigths and biases\n","  hidden_output_0 = tf.nn.relu(tf.matmul(input_X,weights_0)+bias_0)\n","  predicted_y = tf.sigmoid(tf.matmul(hidden_output_0,weights_1) + bias_1)\n","\n","  ##calculate penalty term\n","  series = pd.Series(sensor_sizes)\n","  cumsum = series.cumsum()\n","  penalty=(tf.reduce_sum(tf.square(weights_0[0:sensor_sizes[0]])))**0.5\n","  for i in range(len(sensor_sizes)-1):\n","    penalty=penalty+(tf.reduce_sum(tf.square(weights_0[cumsum[i]:cumsum[i+1]])))**0.5\n","\n","  cumsum =[0]+ list(series.cumsum())\n","  red=0\n","  r_mat=np.array(xvals_train.corr())\n","  rsq_mat=[[elem*elem for elem in inner] for inner in r_mat]\n","  rsq_mat=pd.DataFrame(rsq_mat)\n","  for i in range(len(sensor_sizes)):\n","    for j in range(len(sensor_sizes)):\n","      if j!=i:\n","        red=red+dep(rsq_mat,sensor_sizes,i+1,j+1)*((tf.reduce_sum(tf.square(weights_0[cumsum[j]:cumsum[j+1]])))*(tf.reduce_sum(tf.square(weights_0[cumsum[i]:cumsum[i+1]])))**0.5)\n","    \n","  red=red/(len(sensor_sizes)*(len(sensor_sizes)-1))\n","\n","  loss = tf.reduce_mean(tf.square(predicted_y-tf.convert_to_tensor(yvals_train, dtype=tf.float32))) + regularizer_rate_0*red + regularizer_rate_1*penalty \n","\n","\n","  ## Variable learning rate\n","  learning_rate = tf.train.exponential_decay(starter_learning_rate, 0, 5, 0.85, staircase=True)\n","  ## Adam optimzer for finding the right weight\n","  optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,var_list=[weights_0,weights_1,\n","                                                                         bias_0,bias_1])    \n","  ## Metrics definition\n","  correct_prediction = tf.equal(tf.argmax(yvals_train,1), tf.argmax(predicted_y,1))\n","  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","  training_accuracy = []\n","  training_loss = []\n","  testing_accuracy = []\n","  #s.run(tf.initialize_all_variables)\n","  s.run(tf.compat.v1.global_variables_initializer())\n","  for epoch in range(epochs):    \n","    arr = np.arange(nrow)\n","    np.random.shuffle(arr)\n","    for index in range(0,nrow,batch_size):\n","        s.run(optimizer, {input_X: xvals_train,\n","                          input_y: yvals_train})\n","        \n","    training_accuracy.append(s.run(accuracy, feed_dict= {input_X:xvals_train, \n","                                                         input_y: yvals_train}))\n","    training_loss.append(s.run(loss, {input_X: xvals_train, \n","                                      input_y: yvals_train}))\n","    print(\"Epoch:{0}, Train loss: {1:.2f} Train acc: {2:.3f}\".format(epoch,\n","                                                                    training_loss[epoch],\n","                                                                    training_accuracy[epoch]))\n","   \n","  ## Evaluation of test data\n","  for i in range(len(xvals_test)):\n","    print('Actual:', yvals_test[i], 'Predicted:', np.rint(s.run(predicted_y, feed_dict={input_X: [xvals_test.iloc[i]]})))\n","\n","  y_pred = np.rint(s.run(predicted_y, feed_dict={input_X: xvals_test}))\n","  print(len(y_pred))\n","  print(len(yvals_test))\n","  score = accuracy_score(yvals_test, y_pred)\n"," \n","  print(\"\\nTest Accuracy: {0:f}\\n\".format(score))\n","\n","  w0=weights_0.eval()\n","  w=[]\n","  #w.append(norm(w0[0:sensor_sizes[0]],2))\n","  for i in range(len(sensor_sizes)):\n","    w.append(norm(w0[cumsum[i]:cumsum[i+1]],2))\n","  print(w)\n","  s.close()\n","  return([weights_0,weights_1, bias_0,bias_1])"]},{"cell_type":"markdown","source":[],"metadata":{"id":"Elmas-JV8m2_"}},{"cell_type":"code","source":["func_modified(0,0,10,500,10,3,[2,2],dep_cor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"meZwO8T78nei","executionInfo":{"status":"ok","timestamp":1675775573407,"user_tz":-330,"elapsed":6416,"user":{"displayName":"Aytijhya Saha","userId":"15087240692289809888"}},"outputId":"782494a4-28a7-4774-f3d9-ee6d22ac059b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch:0, Train loss: 0.45 Train acc: 0.317\n","Epoch:1, Train loss: 0.42 Train acc: 0.317\n","Epoch:2, Train loss: 0.40 Train acc: 0.317\n","Epoch:3, Train loss: 0.38 Train acc: 0.317\n","Epoch:4, Train loss: 0.37 Train acc: 0.317\n","Epoch:5, Train loss: 0.37 Train acc: 0.317\n","Epoch:6, Train loss: 0.36 Train acc: 0.317\n","Epoch:7, Train loss: 0.36 Train acc: 0.317\n","Epoch:8, Train loss: 0.35 Train acc: 0.317\n","Epoch:9, Train loss: 0.35 Train acc: 0.317\n","Epoch:10, Train loss: 0.34 Train acc: 0.317\n","Epoch:11, Train loss: 0.34 Train acc: 0.317\n","Epoch:12, Train loss: 0.32 Train acc: 0.317\n","Epoch:13, Train loss: 0.29 Train acc: 0.317\n","Epoch:14, Train loss: 0.24 Train acc: 0.608\n","Epoch:15, Train loss: 0.18 Train acc: 0.683\n","Epoch:16, Train loss: 0.15 Train acc: 0.683\n","Epoch:17, Train loss: 0.14 Train acc: 0.683\n","Epoch:18, Train loss: 0.14 Train acc: 0.683\n","Epoch:19, Train loss: 0.13 Train acc: 0.683\n","Epoch:20, Train loss: 0.13 Train acc: 0.692\n","Epoch:21, Train loss: 0.12 Train acc: 0.700\n","Epoch:22, Train loss: 0.12 Train acc: 0.775\n","Epoch:23, Train loss: 0.11 Train acc: 0.742\n","Epoch:24, Train loss: 0.11 Train acc: 0.733\n","Epoch:25, Train loss: 0.11 Train acc: 0.792\n","Epoch:26, Train loss: 0.11 Train acc: 0.808\n","Epoch:27, Train loss: 0.10 Train acc: 0.817\n","Epoch:28, Train loss: 0.10 Train acc: 0.825\n","Epoch:29, Train loss: 0.10 Train acc: 0.833\n","Epoch:30, Train loss: 0.10 Train acc: 0.850\n","Epoch:31, Train loss: 0.10 Train acc: 0.850\n","Epoch:32, Train loss: 0.10 Train acc: 0.850\n","Epoch:33, Train loss: 0.09 Train acc: 0.867\n","Epoch:34, Train loss: 0.09 Train acc: 0.875\n","Epoch:35, Train loss: 0.09 Train acc: 0.883\n","Epoch:36, Train loss: 0.09 Train acc: 0.892\n","Epoch:37, Train loss: 0.09 Train acc: 0.900\n","Epoch:38, Train loss: 0.09 Train acc: 0.900\n","Epoch:39, Train loss: 0.09 Train acc: 0.917\n","Epoch:40, Train loss: 0.08 Train acc: 0.925\n","Epoch:41, Train loss: 0.08 Train acc: 0.925\n","Epoch:42, Train loss: 0.08 Train acc: 0.925\n","Epoch:43, Train loss: 0.08 Train acc: 0.933\n","Epoch:44, Train loss: 0.08 Train acc: 0.942\n","Epoch:45, Train loss: 0.08 Train acc: 0.942\n","Epoch:46, Train loss: 0.08 Train acc: 0.950\n","Epoch:47, Train loss: 0.08 Train acc: 0.950\n","Epoch:48, Train loss: 0.08 Train acc: 0.958\n","Epoch:49, Train loss: 0.08 Train acc: 0.958\n","Epoch:50, Train loss: 0.08 Train acc: 0.958\n","Epoch:51, Train loss: 0.07 Train acc: 0.958\n","Epoch:52, Train loss: 0.07 Train acc: 0.958\n","Epoch:53, Train loss: 0.07 Train acc: 0.958\n","Epoch:54, Train loss: 0.07 Train acc: 0.958\n","Epoch:55, Train loss: 0.07 Train acc: 0.958\n","Epoch:56, Train loss: 0.07 Train acc: 0.958\n","Epoch:57, Train loss: 0.07 Train acc: 0.958\n","Epoch:58, Train loss: 0.07 Train acc: 0.958\n","Epoch:59, Train loss: 0.07 Train acc: 0.958\n","Epoch:60, Train loss: 0.07 Train acc: 0.958\n","Epoch:61, Train loss: 0.07 Train acc: 0.958\n","Epoch:62, Train loss: 0.07 Train acc: 0.967\n","Epoch:63, Train loss: 0.06 Train acc: 0.967\n","Epoch:64, Train loss: 0.06 Train acc: 0.967\n","Epoch:65, Train loss: 0.06 Train acc: 0.967\n","Epoch:66, Train loss: 0.06 Train acc: 0.967\n","Epoch:67, Train loss: 0.06 Train acc: 0.967\n","Epoch:68, Train loss: 0.06 Train acc: 0.967\n","Epoch:69, Train loss: 0.06 Train acc: 0.975\n","Epoch:70, Train loss: 0.06 Train acc: 0.975\n","Epoch:71, Train loss: 0.06 Train acc: 0.975\n","Epoch:72, Train loss: 0.06 Train acc: 0.975\n","Epoch:73, Train loss: 0.06 Train acc: 0.975\n","Epoch:74, Train loss: 0.06 Train acc: 0.975\n","Epoch:75, Train loss: 0.06 Train acc: 0.975\n","Epoch:76, Train loss: 0.06 Train acc: 0.975\n","Epoch:77, Train loss: 0.06 Train acc: 0.975\n","Epoch:78, Train loss: 0.05 Train acc: 0.975\n","Epoch:79, Train loss: 0.05 Train acc: 0.975\n","Epoch:80, Train loss: 0.05 Train acc: 0.975\n","Epoch:81, Train loss: 0.05 Train acc: 0.975\n","Epoch:82, Train loss: 0.05 Train acc: 0.975\n","Epoch:83, Train loss: 0.05 Train acc: 0.975\n","Epoch:84, Train loss: 0.05 Train acc: 0.975\n","Epoch:85, Train loss: 0.05 Train acc: 0.975\n","Epoch:86, Train loss: 0.05 Train acc: 0.975\n","Epoch:87, Train loss: 0.05 Train acc: 0.975\n","Epoch:88, Train loss: 0.05 Train acc: 0.975\n","Epoch:89, Train loss: 0.05 Train acc: 0.975\n","Epoch:90, Train loss: 0.05 Train acc: 0.975\n","Epoch:91, Train loss: 0.05 Train acc: 0.975\n","Epoch:92, Train loss: 0.05 Train acc: 0.975\n","Epoch:93, Train loss: 0.05 Train acc: 0.975\n","Epoch:94, Train loss: 0.04 Train acc: 0.975\n","Epoch:95, Train loss: 0.04 Train acc: 0.975\n","Epoch:96, Train loss: 0.04 Train acc: 0.975\n","Epoch:97, Train loss: 0.04 Train acc: 0.975\n","Epoch:98, Train loss: 0.04 Train acc: 0.975\n","Epoch:99, Train loss: 0.04 Train acc: 0.975\n","Epoch:100, Train loss: 0.04 Train acc: 0.975\n","Epoch:101, Train loss: 0.04 Train acc: 0.975\n","Epoch:102, Train loss: 0.04 Train acc: 0.975\n","Epoch:103, Train loss: 0.04 Train acc: 0.975\n","Epoch:104, Train loss: 0.04 Train acc: 0.975\n","Epoch:105, Train loss: 0.04 Train acc: 0.975\n","Epoch:106, Train loss: 0.04 Train acc: 0.975\n","Epoch:107, Train loss: 0.04 Train acc: 0.975\n","Epoch:108, Train loss: 0.04 Train acc: 0.975\n","Epoch:109, Train loss: 0.04 Train acc: 0.975\n","Epoch:110, Train loss: 0.04 Train acc: 0.975\n","Epoch:111, Train loss: 0.04 Train acc: 0.975\n","Epoch:112, Train loss: 0.04 Train acc: 0.975\n","Epoch:113, Train loss: 0.03 Train acc: 0.975\n","Epoch:114, Train loss: 0.03 Train acc: 0.975\n","Epoch:115, Train loss: 0.03 Train acc: 0.975\n","Epoch:116, Train loss: 0.03 Train acc: 0.975\n","Epoch:117, Train loss: 0.03 Train acc: 0.975\n","Epoch:118, Train loss: 0.03 Train acc: 0.975\n","Epoch:119, Train loss: 0.03 Train acc: 0.975\n","Epoch:120, Train loss: 0.03 Train acc: 0.975\n","Epoch:121, Train loss: 0.03 Train acc: 0.975\n","Epoch:122, Train loss: 0.03 Train acc: 0.975\n","Epoch:123, Train loss: 0.03 Train acc: 0.975\n","Epoch:124, Train loss: 0.03 Train acc: 0.975\n","Epoch:125, Train loss: 0.03 Train acc: 0.975\n","Epoch:126, Train loss: 0.03 Train acc: 0.975\n","Epoch:127, Train loss: 0.03 Train acc: 0.975\n","Epoch:128, Train loss: 0.03 Train acc: 0.975\n","Epoch:129, Train loss: 0.03 Train acc: 0.975\n","Epoch:130, Train loss: 0.03 Train acc: 0.975\n","Epoch:131, Train loss: 0.03 Train acc: 0.975\n","Epoch:132, Train loss: 0.03 Train acc: 0.975\n","Epoch:133, Train loss: 0.03 Train acc: 0.975\n","Epoch:134, Train loss: 0.03 Train acc: 0.975\n","Epoch:135, Train loss: 0.03 Train acc: 0.975\n","Epoch:136, Train loss: 0.03 Train acc: 0.975\n","Epoch:137, Train loss: 0.03 Train acc: 0.975\n","Epoch:138, Train loss: 0.03 Train acc: 0.975\n","Epoch:139, Train loss: 0.03 Train acc: 0.975\n","Epoch:140, Train loss: 0.03 Train acc: 0.975\n","Epoch:141, Train loss: 0.03 Train acc: 0.975\n","Epoch:142, Train loss: 0.03 Train acc: 0.975\n","Epoch:143, Train loss: 0.03 Train acc: 0.975\n","Epoch:144, Train loss: 0.02 Train acc: 0.975\n","Epoch:145, Train loss: 0.02 Train acc: 0.975\n","Epoch:146, Train loss: 0.02 Train acc: 0.975\n","Epoch:147, Train loss: 0.02 Train acc: 0.975\n","Epoch:148, Train loss: 0.02 Train acc: 0.975\n","Epoch:149, Train loss: 0.02 Train acc: 0.975\n","Epoch:150, Train loss: 0.02 Train acc: 0.975\n","Epoch:151, Train loss: 0.02 Train acc: 0.975\n","Epoch:152, Train loss: 0.02 Train acc: 0.975\n","Epoch:153, Train loss: 0.02 Train acc: 0.975\n","Epoch:154, Train loss: 0.02 Train acc: 0.975\n","Epoch:155, Train loss: 0.02 Train acc: 0.975\n","Epoch:156, Train loss: 0.02 Train acc: 0.975\n","Epoch:157, Train loss: 0.02 Train acc: 0.975\n","Epoch:158, Train loss: 0.02 Train acc: 0.975\n","Epoch:159, Train loss: 0.02 Train acc: 0.975\n","Epoch:160, Train loss: 0.02 Train acc: 0.975\n","Epoch:161, Train loss: 0.02 Train acc: 0.975\n","Epoch:162, Train loss: 0.02 Train acc: 0.975\n","Epoch:163, Train loss: 0.02 Train acc: 0.975\n","Epoch:164, Train loss: 0.02 Train acc: 0.975\n","Epoch:165, Train loss: 0.02 Train acc: 0.975\n","Epoch:166, Train loss: 0.02 Train acc: 0.975\n","Epoch:167, Train loss: 0.02 Train acc: 0.975\n","Epoch:168, Train loss: 0.02 Train acc: 0.975\n","Epoch:169, Train loss: 0.02 Train acc: 0.975\n","Epoch:170, Train loss: 0.02 Train acc: 0.975\n","Epoch:171, Train loss: 0.02 Train acc: 0.975\n","Epoch:172, Train loss: 0.02 Train acc: 0.975\n","Epoch:173, Train loss: 0.02 Train acc: 0.975\n","Epoch:174, Train loss: 0.02 Train acc: 0.975\n","Epoch:175, Train loss: 0.02 Train acc: 0.975\n","Epoch:176, Train loss: 0.02 Train acc: 0.975\n","Epoch:177, Train loss: 0.02 Train acc: 0.975\n","Epoch:178, Train loss: 0.02 Train acc: 0.975\n","Epoch:179, Train loss: 0.02 Train acc: 0.975\n","Epoch:180, Train loss: 0.02 Train acc: 0.975\n","Epoch:181, Train loss: 0.02 Train acc: 0.975\n","Epoch:182, Train loss: 0.02 Train acc: 0.975\n","Epoch:183, Train loss: 0.02 Train acc: 0.975\n","Epoch:184, Train loss: 0.02 Train acc: 0.975\n","Epoch:185, Train loss: 0.02 Train acc: 0.975\n","Epoch:186, Train loss: 0.02 Train acc: 0.975\n","Epoch:187, Train loss: 0.02 Train acc: 0.983\n","Epoch:188, Train loss: 0.02 Train acc: 0.983\n","Epoch:189, Train loss: 0.02 Train acc: 0.983\n","Epoch:190, Train loss: 0.02 Train acc: 0.983\n","Epoch:191, Train loss: 0.02 Train acc: 0.983\n","Epoch:192, Train loss: 0.02 Train acc: 0.983\n","Epoch:193, Train loss: 0.02 Train acc: 0.983\n","Epoch:194, Train loss: 0.02 Train acc: 0.983\n","Epoch:195, Train loss: 0.02 Train acc: 0.983\n","Epoch:196, Train loss: 0.02 Train acc: 0.983\n","Epoch:197, Train loss: 0.02 Train acc: 0.983\n","Epoch:198, Train loss: 0.02 Train acc: 0.983\n","Epoch:199, Train loss: 0.02 Train acc: 0.983\n","Epoch:200, Train loss: 0.02 Train acc: 0.983\n","Epoch:201, Train loss: 0.02 Train acc: 0.983\n","Epoch:202, Train loss: 0.02 Train acc: 0.983\n","Epoch:203, Train loss: 0.02 Train acc: 0.983\n","Epoch:204, Train loss: 0.02 Train acc: 0.983\n","Epoch:205, Train loss: 0.02 Train acc: 0.983\n","Epoch:206, Train loss: 0.02 Train acc: 0.983\n","Epoch:207, Train loss: 0.02 Train acc: 0.983\n","Epoch:208, Train loss: 0.02 Train acc: 0.983\n","Epoch:209, Train loss: 0.02 Train acc: 0.983\n","Epoch:210, Train loss: 0.02 Train acc: 0.983\n","Epoch:211, Train loss: 0.02 Train acc: 0.983\n","Epoch:212, Train loss: 0.02 Train acc: 0.983\n","Epoch:213, Train loss: 0.02 Train acc: 0.983\n","Epoch:214, Train loss: 0.02 Train acc: 0.983\n","Epoch:215, Train loss: 0.02 Train acc: 0.983\n","Epoch:216, Train loss: 0.02 Train acc: 0.983\n","Epoch:217, Train loss: 0.02 Train acc: 0.983\n","Epoch:218, Train loss: 0.02 Train acc: 0.983\n","Epoch:219, Train loss: 0.02 Train acc: 0.983\n","Epoch:220, Train loss: 0.02 Train acc: 0.983\n","Epoch:221, Train loss: 0.02 Train acc: 0.983\n","Epoch:222, Train loss: 0.02 Train acc: 0.983\n","Epoch:223, Train loss: 0.02 Train acc: 0.983\n","Epoch:224, Train loss: 0.02 Train acc: 0.983\n","Epoch:225, Train loss: 0.02 Train acc: 0.983\n","Epoch:226, Train loss: 0.02 Train acc: 0.983\n","Epoch:227, Train loss: 0.02 Train acc: 0.983\n","Epoch:228, Train loss: 0.02 Train acc: 0.983\n","Epoch:229, Train loss: 0.02 Train acc: 0.983\n","Epoch:230, Train loss: 0.02 Train acc: 0.983\n","Epoch:231, Train loss: 0.02 Train acc: 0.983\n","Epoch:232, Train loss: 0.02 Train acc: 0.983\n","Epoch:233, Train loss: 0.02 Train acc: 0.983\n","Epoch:234, Train loss: 0.02 Train acc: 0.983\n","Epoch:235, Train loss: 0.02 Train acc: 0.983\n","Epoch:236, Train loss: 0.01 Train acc: 0.983\n","Epoch:237, Train loss: 0.01 Train acc: 0.983\n","Epoch:238, Train loss: 0.01 Train acc: 0.983\n","Epoch:239, Train loss: 0.01 Train acc: 0.983\n","Epoch:240, Train loss: 0.01 Train acc: 0.983\n","Epoch:241, Train loss: 0.01 Train acc: 0.983\n","Epoch:242, Train loss: 0.01 Train acc: 0.983\n","Epoch:243, Train loss: 0.01 Train acc: 0.983\n","Epoch:244, Train loss: 0.01 Train acc: 0.983\n","Epoch:245, Train loss: 0.01 Train acc: 0.983\n","Epoch:246, Train loss: 0.01 Train acc: 0.983\n","Epoch:247, Train loss: 0.01 Train acc: 0.983\n","Epoch:248, Train loss: 0.01 Train acc: 0.983\n","Epoch:249, Train loss: 0.01 Train acc: 0.983\n","Epoch:250, Train loss: 0.01 Train acc: 0.983\n","Epoch:251, Train loss: 0.01 Train acc: 0.983\n","Epoch:252, Train loss: 0.01 Train acc: 0.983\n","Epoch:253, Train loss: 0.01 Train acc: 0.983\n","Epoch:254, Train loss: 0.01 Train acc: 0.983\n","Epoch:255, Train loss: 0.01 Train acc: 0.983\n","Epoch:256, Train loss: 0.01 Train acc: 0.983\n","Epoch:257, Train loss: 0.01 Train acc: 0.983\n","Epoch:258, Train loss: 0.01 Train acc: 0.983\n","Epoch:259, Train loss: 0.01 Train acc: 0.983\n","Epoch:260, Train loss: 0.01 Train acc: 0.983\n","Epoch:261, Train loss: 0.01 Train acc: 0.983\n","Epoch:262, Train loss: 0.01 Train acc: 0.983\n","Epoch:263, Train loss: 0.01 Train acc: 0.983\n","Epoch:264, Train loss: 0.01 Train acc: 0.983\n","Epoch:265, Train loss: 0.01 Train acc: 0.983\n","Epoch:266, Train loss: 0.01 Train acc: 0.983\n","Epoch:267, Train loss: 0.01 Train acc: 0.983\n","Epoch:268, Train loss: 0.01 Train acc: 0.983\n","Epoch:269, Train loss: 0.01 Train acc: 0.983\n","Epoch:270, Train loss: 0.01 Train acc: 0.983\n","Epoch:271, Train loss: 0.01 Train acc: 0.983\n","Epoch:272, Train loss: 0.01 Train acc: 0.983\n","Epoch:273, Train loss: 0.01 Train acc: 0.983\n","Epoch:274, Train loss: 0.01 Train acc: 0.983\n","Epoch:275, Train loss: 0.01 Train acc: 0.983\n","Epoch:276, Train loss: 0.01 Train acc: 0.983\n","Epoch:277, Train loss: 0.01 Train acc: 0.983\n","Epoch:278, Train loss: 0.01 Train acc: 0.983\n","Epoch:279, Train loss: 0.01 Train acc: 0.983\n","Epoch:280, Train loss: 0.01 Train acc: 0.983\n","Epoch:281, Train loss: 0.01 Train acc: 0.983\n","Epoch:282, Train loss: 0.01 Train acc: 0.983\n","Epoch:283, Train loss: 0.01 Train acc: 0.983\n","Epoch:284, Train loss: 0.01 Train acc: 0.983\n","Epoch:285, Train loss: 0.01 Train acc: 0.983\n","Epoch:286, Train loss: 0.01 Train acc: 0.983\n","Epoch:287, Train loss: 0.01 Train acc: 0.983\n","Epoch:288, Train loss: 0.01 Train acc: 0.983\n","Epoch:289, Train loss: 0.01 Train acc: 0.983\n","Epoch:290, Train loss: 0.01 Train acc: 0.983\n","Epoch:291, Train loss: 0.01 Train acc: 0.983\n","Epoch:292, Train loss: 0.01 Train acc: 0.983\n","Epoch:293, Train loss: 0.01 Train acc: 0.983\n","Epoch:294, Train loss: 0.01 Train acc: 0.983\n","Epoch:295, Train loss: 0.01 Train acc: 0.983\n","Epoch:296, Train loss: 0.01 Train acc: 0.983\n","Epoch:297, Train loss: 0.01 Train acc: 0.983\n","Epoch:298, Train loss: 0.01 Train acc: 0.983\n","Epoch:299, Train loss: 0.01 Train acc: 0.983\n","Epoch:300, Train loss: 0.01 Train acc: 0.983\n","Epoch:301, Train loss: 0.01 Train acc: 0.983\n","Epoch:302, Train loss: 0.01 Train acc: 0.983\n","Epoch:303, Train loss: 0.01 Train acc: 0.983\n","Epoch:304, Train loss: 0.01 Train acc: 0.983\n","Epoch:305, Train loss: 0.01 Train acc: 0.983\n","Epoch:306, Train loss: 0.01 Train acc: 0.983\n","Epoch:307, Train loss: 0.01 Train acc: 0.983\n","Epoch:308, Train loss: 0.01 Train acc: 0.983\n","Epoch:309, Train loss: 0.01 Train acc: 0.983\n","Epoch:310, Train loss: 0.01 Train acc: 0.983\n","Epoch:311, Train loss: 0.01 Train acc: 0.983\n","Epoch:312, Train loss: 0.01 Train acc: 0.983\n","Epoch:313, Train loss: 0.01 Train acc: 0.983\n","Epoch:314, Train loss: 0.01 Train acc: 0.983\n","Epoch:315, Train loss: 0.01 Train acc: 0.983\n","Epoch:316, Train loss: 0.01 Train acc: 0.983\n","Epoch:317, Train loss: 0.01 Train acc: 0.983\n","Epoch:318, Train loss: 0.01 Train acc: 0.983\n","Epoch:319, Train loss: 0.01 Train acc: 0.983\n","Epoch:320, Train loss: 0.01 Train acc: 0.983\n","Epoch:321, Train loss: 0.01 Train acc: 0.983\n","Epoch:322, Train loss: 0.01 Train acc: 0.983\n","Epoch:323, Train loss: 0.01 Train acc: 0.983\n","Epoch:324, Train loss: 0.01 Train acc: 0.983\n","Epoch:325, Train loss: 0.01 Train acc: 0.983\n","Epoch:326, Train loss: 0.01 Train acc: 0.983\n","Epoch:327, Train loss: 0.01 Train acc: 0.983\n","Epoch:328, Train loss: 0.01 Train acc: 0.983\n","Epoch:329, Train loss: 0.01 Train acc: 0.983\n","Epoch:330, Train loss: 0.01 Train acc: 0.983\n","Epoch:331, Train loss: 0.01 Train acc: 0.983\n","Epoch:332, Train loss: 0.01 Train acc: 0.983\n","Epoch:333, Train loss: 0.01 Train acc: 0.983\n","Epoch:334, Train loss: 0.01 Train acc: 0.983\n","Epoch:335, Train loss: 0.01 Train acc: 0.983\n","Epoch:336, Train loss: 0.01 Train acc: 0.983\n","Epoch:337, Train loss: 0.01 Train acc: 0.983\n","Epoch:338, Train loss: 0.01 Train acc: 0.983\n","Epoch:339, Train loss: 0.01 Train acc: 0.983\n","Epoch:340, Train loss: 0.01 Train acc: 0.983\n","Epoch:341, Train loss: 0.01 Train acc: 0.983\n","Epoch:342, Train loss: 0.01 Train acc: 0.983\n","Epoch:343, Train loss: 0.01 Train acc: 0.983\n","Epoch:344, Train loss: 0.01 Train acc: 0.983\n","Epoch:345, Train loss: 0.01 Train acc: 0.983\n","Epoch:346, Train loss: 0.01 Train acc: 0.983\n","Epoch:347, Train loss: 0.01 Train acc: 0.983\n","Epoch:348, Train loss: 0.01 Train acc: 0.983\n","Epoch:349, Train loss: 0.01 Train acc: 0.983\n","Epoch:350, Train loss: 0.01 Train acc: 0.983\n","Epoch:351, Train loss: 0.01 Train acc: 0.983\n","Epoch:352, Train loss: 0.01 Train acc: 0.983\n","Epoch:353, Train loss: 0.01 Train acc: 0.983\n","Epoch:354, Train loss: 0.01 Train acc: 0.983\n","Epoch:355, Train loss: 0.01 Train acc: 0.983\n","Epoch:356, Train loss: 0.01 Train acc: 0.983\n","Epoch:357, Train loss: 0.01 Train acc: 0.983\n","Epoch:358, Train loss: 0.01 Train acc: 0.983\n","Epoch:359, Train loss: 0.01 Train acc: 0.983\n","Epoch:360, Train loss: 0.01 Train acc: 0.983\n","Epoch:361, Train loss: 0.01 Train acc: 0.983\n","Epoch:362, Train loss: 0.01 Train acc: 0.983\n","Epoch:363, Train loss: 0.01 Train acc: 0.983\n","Epoch:364, Train loss: 0.01 Train acc: 0.983\n","Epoch:365, Train loss: 0.01 Train acc: 0.983\n","Epoch:366, Train loss: 0.01 Train acc: 0.983\n","Epoch:367, Train loss: 0.01 Train acc: 0.983\n","Epoch:368, Train loss: 0.01 Train acc: 0.983\n","Epoch:369, Train loss: 0.01 Train acc: 0.983\n","Epoch:370, Train loss: 0.01 Train acc: 0.983\n","Epoch:371, Train loss: 0.01 Train acc: 0.983\n","Epoch:372, Train loss: 0.01 Train acc: 0.983\n","Epoch:373, Train loss: 0.01 Train acc: 0.983\n","Epoch:374, Train loss: 0.01 Train acc: 0.983\n","Epoch:375, Train loss: 0.01 Train acc: 0.983\n","Epoch:376, Train loss: 0.01 Train acc: 0.975\n","Epoch:377, Train loss: 0.01 Train acc: 0.975\n","Epoch:378, Train loss: 0.01 Train acc: 0.975\n","Epoch:379, Train loss: 0.01 Train acc: 0.975\n","Epoch:380, Train loss: 0.01 Train acc: 0.975\n","Epoch:381, Train loss: 0.01 Train acc: 0.975\n","Epoch:382, Train loss: 0.01 Train acc: 0.975\n","Epoch:383, Train loss: 0.01 Train acc: 0.975\n","Epoch:384, Train loss: 0.01 Train acc: 0.975\n","Epoch:385, Train loss: 0.01 Train acc: 0.975\n","Epoch:386, Train loss: 0.01 Train acc: 0.975\n","Epoch:387, Train loss: 0.01 Train acc: 0.975\n","Epoch:388, Train loss: 0.01 Train acc: 0.975\n","Epoch:389, Train loss: 0.01 Train acc: 0.975\n","Epoch:390, Train loss: 0.01 Train acc: 0.975\n","Epoch:391, Train loss: 0.01 Train acc: 0.975\n","Epoch:392, Train loss: 0.01 Train acc: 0.975\n","Epoch:393, Train loss: 0.01 Train acc: 0.975\n","Epoch:394, Train loss: 0.01 Train acc: 0.975\n","Epoch:395, Train loss: 0.01 Train acc: 0.975\n","Epoch:396, Train loss: 0.01 Train acc: 0.975\n","Epoch:397, Train loss: 0.01 Train acc: 0.975\n","Epoch:398, Train loss: 0.01 Train acc: 0.975\n","Epoch:399, Train loss: 0.01 Train acc: 0.975\n","Epoch:400, Train loss: 0.01 Train acc: 0.975\n","Epoch:401, Train loss: 0.01 Train acc: 0.983\n","Epoch:402, Train loss: 0.01 Train acc: 0.975\n","Epoch:403, Train loss: 0.01 Train acc: 0.983\n","Epoch:404, Train loss: 0.01 Train acc: 0.983\n","Epoch:405, Train loss: 0.01 Train acc: 0.983\n","Epoch:406, Train loss: 0.01 Train acc: 0.983\n","Epoch:407, Train loss: 0.01 Train acc: 0.983\n","Epoch:408, Train loss: 0.01 Train acc: 0.975\n","Epoch:409, Train loss: 0.01 Train acc: 0.975\n","Epoch:410, Train loss: 0.01 Train acc: 0.983\n","Epoch:411, Train loss: 0.01 Train acc: 0.975\n","Epoch:412, Train loss: 0.01 Train acc: 0.975\n","Epoch:413, Train loss: 0.01 Train acc: 0.975\n","Epoch:414, Train loss: 0.01 Train acc: 0.975\n","Epoch:415, Train loss: 0.01 Train acc: 0.975\n","Epoch:416, Train loss: 0.01 Train acc: 0.975\n","Epoch:417, Train loss: 0.01 Train acc: 0.975\n","Epoch:418, Train loss: 0.01 Train acc: 0.975\n","Epoch:419, Train loss: 0.01 Train acc: 0.975\n","Epoch:420, Train loss: 0.01 Train acc: 0.975\n","Epoch:421, Train loss: 0.01 Train acc: 0.975\n","Epoch:422, Train loss: 0.01 Train acc: 0.975\n","Epoch:423, Train loss: 0.01 Train acc: 0.975\n","Epoch:424, Train loss: 0.01 Train acc: 0.975\n","Epoch:425, Train loss: 0.01 Train acc: 0.975\n","Epoch:426, Train loss: 0.01 Train acc: 0.975\n","Epoch:427, Train loss: 0.01 Train acc: 0.975\n","Epoch:428, Train loss: 0.01 Train acc: 0.975\n","Epoch:429, Train loss: 0.01 Train acc: 0.975\n","Epoch:430, Train loss: 0.01 Train acc: 0.975\n","Epoch:431, Train loss: 0.01 Train acc: 0.975\n","Epoch:432, Train loss: 0.01 Train acc: 0.975\n","Epoch:433, Train loss: 0.01 Train acc: 0.975\n","Epoch:434, Train loss: 0.01 Train acc: 0.975\n","Epoch:435, Train loss: 0.01 Train acc: 0.975\n","Epoch:436, Train loss: 0.01 Train acc: 0.975\n","Epoch:437, Train loss: 0.01 Train acc: 0.975\n","Epoch:438, Train loss: 0.01 Train acc: 0.975\n","Epoch:439, Train loss: 0.01 Train acc: 0.975\n","Epoch:440, Train loss: 0.01 Train acc: 0.975\n","Epoch:441, Train loss: 0.01 Train acc: 0.975\n","Epoch:442, Train loss: 0.01 Train acc: 0.975\n","Epoch:443, Train loss: 0.01 Train acc: 0.975\n","Epoch:444, Train loss: 0.01 Train acc: 0.975\n","Epoch:445, Train loss: 0.01 Train acc: 0.975\n","Epoch:446, Train loss: 0.01 Train acc: 0.975\n","Epoch:447, Train loss: 0.01 Train acc: 0.975\n","Epoch:448, Train loss: 0.01 Train acc: 0.975\n","Epoch:449, Train loss: 0.01 Train acc: 0.975\n","Epoch:450, Train loss: 0.01 Train acc: 0.975\n","Epoch:451, Train loss: 0.01 Train acc: 0.975\n","Epoch:452, Train loss: 0.01 Train acc: 0.975\n","Epoch:453, Train loss: 0.01 Train acc: 0.975\n","Epoch:454, Train loss: 0.01 Train acc: 0.983\n","Epoch:455, Train loss: 0.01 Train acc: 0.983\n","Epoch:456, Train loss: 0.01 Train acc: 0.975\n","Epoch:457, Train loss: 0.01 Train acc: 0.983\n","Epoch:458, Train loss: 0.01 Train acc: 0.983\n","Epoch:459, Train loss: 0.01 Train acc: 0.983\n","Epoch:460, Train loss: 0.01 Train acc: 0.983\n","Epoch:461, Train loss: 0.01 Train acc: 0.983\n","Epoch:462, Train loss: 0.01 Train acc: 0.983\n","Epoch:463, Train loss: 0.01 Train acc: 0.983\n","Epoch:464, Train loss: 0.01 Train acc: 0.983\n","Epoch:465, Train loss: 0.01 Train acc: 0.983\n","Epoch:466, Train loss: 0.01 Train acc: 0.983\n","Epoch:467, Train loss: 0.01 Train acc: 0.983\n","Epoch:468, Train loss: 0.01 Train acc: 0.983\n","Epoch:469, Train loss: 0.01 Train acc: 0.983\n","Epoch:470, Train loss: 0.01 Train acc: 0.983\n","Epoch:471, Train loss: 0.01 Train acc: 0.983\n","Epoch:472, Train loss: 0.01 Train acc: 0.983\n","Epoch:473, Train loss: 0.01 Train acc: 0.983\n","Epoch:474, Train loss: 0.01 Train acc: 0.983\n","Epoch:475, Train loss: 0.01 Train acc: 0.983\n","Epoch:476, Train loss: 0.01 Train acc: 0.983\n","Epoch:477, Train loss: 0.01 Train acc: 0.983\n","Epoch:478, Train loss: 0.01 Train acc: 0.983\n","Epoch:479, Train loss: 0.01 Train acc: 0.983\n","Epoch:480, Train loss: 0.01 Train acc: 0.983\n","Epoch:481, Train loss: 0.01 Train acc: 0.983\n","Epoch:482, Train loss: 0.01 Train acc: 0.983\n","Epoch:483, Train loss: 0.01 Train acc: 0.983\n","Epoch:484, Train loss: 0.01 Train acc: 0.983\n","Epoch:485, Train loss: 0.01 Train acc: 0.983\n","Epoch:486, Train loss: 0.01 Train acc: 0.983\n","Epoch:487, Train loss: 0.01 Train acc: 0.983\n","Epoch:488, Train loss: 0.01 Train acc: 0.983\n","Epoch:489, Train loss: 0.01 Train acc: 0.983\n","Epoch:490, Train loss: 0.01 Train acc: 0.983\n","Epoch:491, Train loss: 0.01 Train acc: 0.983\n","Epoch:492, Train loss: 0.01 Train acc: 0.983\n","Epoch:493, Train loss: 0.01 Train acc: 0.983\n","Epoch:494, Train loss: 0.01 Train acc: 0.983\n","Epoch:495, Train loss: 0.01 Train acc: 0.983\n","Epoch:496, Train loss: 0.01 Train acc: 0.983\n","Epoch:497, Train loss: 0.01 Train acc: 0.983\n","Epoch:498, Train loss: 0.01 Train acc: 0.983\n","Epoch:499, Train loss: 0.01 Train acc: 0.983\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","30\n","30\n","\n","Test Accuracy: 1.000000\n","\n","[3.3349283, 4.8964806]\n"]},{"output_type":"execute_result","data":{"text/plain":["[<tf.Variable 'Variable_32:0' shape=(4, 10) dtype=float32_ref>,\n"," <tf.Variable 'Variable_34:0' shape=(10, 3) dtype=float32_ref>,\n"," <tf.Variable 'Variable_33:0' shape=(10,) dtype=float32_ref>,\n"," <tf.Variable 'Variable_35:0' shape=(3,) dtype=float32_ref>]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MyxuLIffbVBy"},"outputs":[],"source":["def func_modified2(regularizer_rate_0,regularizer_rate_1,num_layers_0, epochs, batch_size, num_classes, sensor_sizes, dep, xvals, yvals, reduction):\n","\n","  from numpy.linalg import norm\n","  import keras\n","  from keras.layers import Activation, Dense\n","  import numpy as np\n","  import pandas as pd\n","  import tensorflow as tf\n","  from sklearn.metrics import accuracy_score\n","  from tensorflow.keras.layers import Dense, Activation\n","  import tensorflow.compat.v1 as tf\n","  tf.disable_v2_behavior()\n","  from sklearn.model_selection import train_test_split\n","\n","  xvals_train, xvals_test,yvals_train, yvals_test = train_test_split(xvals,yvals,random_state=None, test_size=0.2,  shuffle=True)\n","                                                                     \n","  starter_learning_rate = 0.001\n","  num_features=sum(sensor_sizes)\n","  nrow=len(yvals_train)\n","  num_output=num_classes\n","\n","  input_X = tf.placeholder('float32',shape =(None,num_features),name=\"input_X\")\n","  input_y = tf.placeholder('float32',shape = (None,num_classes),name='input_Y')\n","\n","  s=tf.compat.v1.InteractiveSession()\n","  ## Weights initialized by random normal function with std_dev = 1/sqrt(number of input features)\n","  weights_0 = tf.Variable(tf.random.normal([num_features,num_layers_0], stddev=(1/tf.sqrt(float(num_features)))))\n","  bias_0 = tf.Variable(tf.random.normal([num_layers_0]))\n","  weights_1 = tf.Variable(tf.random.normal([num_layers_0,num_output], stddev=(1/tf.sqrt(float(num_layers_0)))))\n","  bias_1 = tf.Variable(tf.random.normal([num_output]))\n","\n","  ## Initializing weigths and biases\n","  hidden_output_0 = tf.nn.relu(tf.matmul(input_X,weights_0)+bias_0)\n","  predicted_y = tf.sigmoid(tf.matmul(hidden_output_0,weights_1) + bias_1)\n","\n","  ##calculate penalty terms\n","  series = pd.Series(sensor_sizes)\n","  cumsum = series.cumsum()\n","  penalty=(tf.reduce_sum(tf.square(weights_0[0:sensor_sizes[0]])))**0.5\n","  for i in range(len(sensor_sizes)-1):\n","    penalty=penalty+(tf.reduce_sum(tf.square(weights_0[cumsum[i]:cumsum[i+1]])))**0.5\n","\n","  cumsum =[0]+ list(series.cumsum())\n","  red=0\n","  r_mat=np.array(xvals_train.corr())\n","  rsq_mat=[[elem*elem for elem in inner] for inner in r_mat]\n","  rsq_mat=pd.DataFrame(rsq_mat)\n","  for i in range(len(sensor_sizes)):\n","    for j in range(len(sensor_sizes)):\n","      if j!=i:\n","        red=red+dep(rsq_mat,sensor_sizes,i+1,j+1)*((tf.reduce_sum(tf.square(weights_0[cumsum[j]:cumsum[j+1]])))*(tf.reduce_sum(tf.square(weights_0[cumsum[i]:cumsum[i+1]])))**0.5)\n","\n","  if len(sensor_sizes)>1:\n","    red=red/(len(sensor_sizes)*(len(sensor_sizes)-1))\n","\n","  loss = tf.reduce_mean(tf.square(predicted_y-tf.convert_to_tensor(yvals_train, dtype=tf.float32))) + regularizer_rate_0*red + regularizer_rate_1*penalty \n","\n","\n","  ## Variable learning rate\n","  learning_rate = tf.train.exponential_decay(starter_learning_rate, 0, 5, 0.85, staircase=True)\n","  ## Adam optimzer for finding the right weight\n","  optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,var_list=[weights_0,weights_1,\n","                                                                         bias_0,bias_1])    \n","  ## Metrics definition\n","  correct_prediction = tf.equal(tf.argmax(yvals_train,1), tf.argmax(predicted_y,1))\n","  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","  training_accuracy = []\n","  training_loss = []\n","  testing_accuracy = []\n","  #s.run(tf.initialize_all_variables)\n","  s.run(tf.compat.v1.global_variables_initializer())\n","  for epoch in range(epochs):    \n","    arr = np.arange(nrow)\n","    np.random.shuffle(arr)\n","    for index in range(0,nrow,batch_size):\n","        s.run(optimizer, {input_X: xvals_train,\n","                          input_y: yvals_train})\n","        \n","    training_accuracy.append(s.run(accuracy, feed_dict= {input_X:xvals_train, \n","                                                         input_y: yvals_train}))\n","    training_loss.append(s.run(loss, {input_X: xvals_train, \n","                                      input_y: yvals_train}))\n","    print(\"Epoch:{0}, Train loss: {1:.2f} Train acc: {2:.3f}\".format(epoch,\n","                                                                    training_loss[epoch],\n","                                                                    training_accuracy[epoch]))\n","   \n","  ## Evaluation of test data\n","  for i in range(len(xvals_test)):\n","    print('Actual:', yvals_test[i], 'Predicted:', np.rint(s.run(predicted_y, feed_dict={input_X: [xvals_test.iloc[i]]})))\n","\n","  y_pred = np.rint(s.run(predicted_y, feed_dict={input_X: xvals_test}))\n","\n","  testacc = accuracy_score(yvals_test, y_pred)\n"," \n","  print(\"\\nTest Accuracy: {0:f}\\n\".format(testacc))\n","\n","  w0=weights_0.eval()\n","  w=[]\n","  #w.append(norm(w0[0:sensor_sizes[0]],2))\n","  for i in range(len(sensor_sizes)):\n","    w.append(norm(w0[cumsum[i]:cumsum[i+1]],2))\n","  print(w)\n","  #Feature selection\n","  if reduction==True:\n","    v=[i for i,x in enumerate(w) if x > 0.1*max(w)]\n","    selected=[]\n","    for i in v:\n","      selected.append(xvals.iloc[:,range(cumsum[i],cumsum[i+1])])\n","    print(selected[0])\n","    xvals_reduced=pd.concat(selected,ignore_index=True, axis=1)\n","    print(xvals_reduced)\n","    acc=0\n","    sensor_sizes_red=[sensor_sizes[i] for i in v]\n","    for i in range(10):\n","      acc=acc+func_modified2(regularizer_rate_0,regularizer_rate_1,num_layers_0, epochs, batch_size, num_classes, sensor_sizes_red,dep_cor,xvals_reduced,yvals,reduction=False)\n","    return(acc/10)\n","  else:\n","    return(testacc)"]},{"cell_type":"code","source":["func_modified2(0.1,0.11,10,500,10,3,[2,2],dep_cor,xvals,yvals,False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2JmFw0_Aoz7","executionInfo":{"status":"ok","timestamp":1675775773470,"user_tz":-330,"elapsed":7320,"user":{"displayName":"Aytijhya Saha","userId":"15087240692289809888"}},"outputId":"efc271b6-3b5b-47e9-eec2-70ad63635941"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch:0, Train loss: 1.48 Train acc: 0.333\n","Epoch:1, Train loss: 1.42 Train acc: 0.333\n","Epoch:2, Train loss: 1.38 Train acc: 0.333\n","Epoch:3, Train loss: 1.33 Train acc: 0.417\n","Epoch:4, Train loss: 1.28 Train acc: 0.600\n","Epoch:5, Train loss: 1.24 Train acc: 0.658\n","Epoch:6, Train loss: 1.20 Train acc: 0.667\n","Epoch:7, Train loss: 1.16 Train acc: 0.675\n","Epoch:8, Train loss: 1.12 Train acc: 0.675\n","Epoch:9, Train loss: 1.08 Train acc: 0.675\n","Epoch:10, Train loss: 1.05 Train acc: 0.683\n","Epoch:11, Train loss: 1.01 Train acc: 0.767\n","Epoch:12, Train loss: 0.98 Train acc: 0.933\n","Epoch:13, Train loss: 0.96 Train acc: 0.967\n","Epoch:14, Train loss: 0.93 Train acc: 0.925\n","Epoch:15, Train loss: 0.91 Train acc: 0.875\n","Epoch:16, Train loss: 0.89 Train acc: 0.858\n","Epoch:17, Train loss: 0.86 Train acc: 0.850\n","Epoch:18, Train loss: 0.84 Train acc: 0.842\n","Epoch:19, Train loss: 0.82 Train acc: 0.842\n","Epoch:20, Train loss: 0.80 Train acc: 0.842\n","Epoch:21, Train loss: 0.79 Train acc: 0.817\n","Epoch:22, Train loss: 0.77 Train acc: 0.817\n","Epoch:23, Train loss: 0.75 Train acc: 0.783\n","Epoch:24, Train loss: 0.74 Train acc: 0.775\n","Epoch:25, Train loss: 0.72 Train acc: 0.758\n","Epoch:26, Train loss: 0.70 Train acc: 0.758\n","Epoch:27, Train loss: 0.69 Train acc: 0.742\n","Epoch:28, Train loss: 0.68 Train acc: 0.742\n","Epoch:29, Train loss: 0.66 Train acc: 0.733\n","Epoch:30, Train loss: 0.65 Train acc: 0.733\n","Epoch:31, Train loss: 0.64 Train acc: 0.725\n","Epoch:32, Train loss: 0.62 Train acc: 0.717\n","Epoch:33, Train loss: 0.61 Train acc: 0.725\n","Epoch:34, Train loss: 0.60 Train acc: 0.725\n","Epoch:35, Train loss: 0.59 Train acc: 0.725\n","Epoch:36, Train loss: 0.58 Train acc: 0.725\n","Epoch:37, Train loss: 0.57 Train acc: 0.733\n","Epoch:38, Train loss: 0.56 Train acc: 0.733\n","Epoch:39, Train loss: 0.55 Train acc: 0.733\n","Epoch:40, Train loss: 0.54 Train acc: 0.733\n","Epoch:41, Train loss: 0.53 Train acc: 0.725\n","Epoch:42, Train loss: 0.52 Train acc: 0.725\n","Epoch:43, Train loss: 0.51 Train acc: 0.725\n","Epoch:44, Train loss: 0.50 Train acc: 0.725\n","Epoch:45, Train loss: 0.49 Train acc: 0.725\n","Epoch:46, Train loss: 0.49 Train acc: 0.725\n","Epoch:47, Train loss: 0.48 Train acc: 0.725\n","Epoch:48, Train loss: 0.47 Train acc: 0.733\n","Epoch:49, Train loss: 0.46 Train acc: 0.733\n","Epoch:50, Train loss: 0.46 Train acc: 0.733\n","Epoch:51, Train loss: 0.45 Train acc: 0.733\n","Epoch:52, Train loss: 0.44 Train acc: 0.733\n","Epoch:53, Train loss: 0.43 Train acc: 0.733\n","Epoch:54, Train loss: 0.43 Train acc: 0.733\n","Epoch:55, Train loss: 0.42 Train acc: 0.733\n","Epoch:56, Train loss: 0.42 Train acc: 0.733\n","Epoch:57, Train loss: 0.41 Train acc: 0.742\n","Epoch:58, Train loss: 0.40 Train acc: 0.742\n","Epoch:59, Train loss: 0.40 Train acc: 0.742\n","Epoch:60, Train loss: 0.39 Train acc: 0.742\n","Epoch:61, Train loss: 0.39 Train acc: 0.742\n","Epoch:62, Train loss: 0.38 Train acc: 0.742\n","Epoch:63, Train loss: 0.38 Train acc: 0.742\n","Epoch:64, Train loss: 0.37 Train acc: 0.742\n","Epoch:65, Train loss: 0.37 Train acc: 0.742\n","Epoch:66, Train loss: 0.36 Train acc: 0.742\n","Epoch:67, Train loss: 0.36 Train acc: 0.742\n","Epoch:68, Train loss: 0.35 Train acc: 0.742\n","Epoch:69, Train loss: 0.35 Train acc: 0.742\n","Epoch:70, Train loss: 0.34 Train acc: 0.750\n","Epoch:71, Train loss: 0.34 Train acc: 0.750\n","Epoch:72, Train loss: 0.33 Train acc: 0.750\n","Epoch:73, Train loss: 0.33 Train acc: 0.750\n","Epoch:74, Train loss: 0.32 Train acc: 0.750\n","Epoch:75, Train loss: 0.32 Train acc: 0.750\n","Epoch:76, Train loss: 0.32 Train acc: 0.750\n","Epoch:77, Train loss: 0.31 Train acc: 0.750\n","Epoch:78, Train loss: 0.31 Train acc: 0.750\n","Epoch:79, Train loss: 0.30 Train acc: 0.750\n","Epoch:80, Train loss: 0.30 Train acc: 0.750\n","Epoch:81, Train loss: 0.30 Train acc: 0.750\n","Epoch:82, Train loss: 0.29 Train acc: 0.750\n","Epoch:83, Train loss: 0.29 Train acc: 0.750\n","Epoch:84, Train loss: 0.29 Train acc: 0.742\n","Epoch:85, Train loss: 0.28 Train acc: 0.742\n","Epoch:86, Train loss: 0.28 Train acc: 0.742\n","Epoch:87, Train loss: 0.28 Train acc: 0.742\n","Epoch:88, Train loss: 0.27 Train acc: 0.742\n","Epoch:89, Train loss: 0.27 Train acc: 0.742\n","Epoch:90, Train loss: 0.27 Train acc: 0.750\n","Epoch:91, Train loss: 0.26 Train acc: 0.750\n","Epoch:92, Train loss: 0.26 Train acc: 0.750\n","Epoch:93, Train loss: 0.26 Train acc: 0.750\n","Epoch:94, Train loss: 0.25 Train acc: 0.750\n","Epoch:95, Train loss: 0.25 Train acc: 0.767\n","Epoch:96, Train loss: 0.24 Train acc: 0.750\n","Epoch:97, Train loss: 0.24 Train acc: 0.750\n","Epoch:98, Train loss: 0.24 Train acc: 0.750\n","Epoch:99, Train loss: 0.24 Train acc: 0.767\n","Epoch:100, Train loss: 0.23 Train acc: 0.767\n","Epoch:101, Train loss: 0.23 Train acc: 0.767\n","Epoch:102, Train loss: 0.23 Train acc: 0.767\n","Epoch:103, Train loss: 0.23 Train acc: 0.767\n","Epoch:104, Train loss: 0.22 Train acc: 0.775\n","Epoch:105, Train loss: 0.22 Train acc: 0.775\n","Epoch:106, Train loss: 0.22 Train acc: 0.775\n","Epoch:107, Train loss: 0.22 Train acc: 0.792\n","Epoch:108, Train loss: 0.22 Train acc: 0.792\n","Epoch:109, Train loss: 0.21 Train acc: 0.792\n","Epoch:110, Train loss: 0.21 Train acc: 0.817\n","Epoch:111, Train loss: 0.21 Train acc: 0.825\n","Epoch:112, Train loss: 0.21 Train acc: 0.825\n","Epoch:113, Train loss: 0.21 Train acc: 0.833\n","Epoch:114, Train loss: 0.21 Train acc: 0.833\n","Epoch:115, Train loss: 0.21 Train acc: 0.833\n","Epoch:116, Train loss: 0.20 Train acc: 0.833\n","Epoch:117, Train loss: 0.20 Train acc: 0.833\n","Epoch:118, Train loss: 0.20 Train acc: 0.833\n","Epoch:119, Train loss: 0.20 Train acc: 0.842\n","Epoch:120, Train loss: 0.20 Train acc: 0.842\n","Epoch:121, Train loss: 0.20 Train acc: 0.842\n","Epoch:122, Train loss: 0.20 Train acc: 0.842\n","Epoch:123, Train loss: 0.20 Train acc: 0.850\n","Epoch:124, Train loss: 0.19 Train acc: 0.850\n","Epoch:125, Train loss: 0.19 Train acc: 0.850\n","Epoch:126, Train loss: 0.19 Train acc: 0.850\n","Epoch:127, Train loss: 0.19 Train acc: 0.850\n","Epoch:128, Train loss: 0.19 Train acc: 0.850\n","Epoch:129, Train loss: 0.19 Train acc: 0.850\n","Epoch:130, Train loss: 0.19 Train acc: 0.850\n","Epoch:131, Train loss: 0.19 Train acc: 0.900\n","Epoch:132, Train loss: 0.18 Train acc: 0.900\n","Epoch:133, Train loss: 0.18 Train acc: 0.900\n","Epoch:134, Train loss: 0.18 Train acc: 0.900\n","Epoch:135, Train loss: 0.18 Train acc: 0.900\n","Epoch:136, Train loss: 0.18 Train acc: 0.908\n","Epoch:137, Train loss: 0.18 Train acc: 0.908\n","Epoch:138, Train loss: 0.18 Train acc: 0.908\n","Epoch:139, Train loss: 0.18 Train acc: 0.908\n","Epoch:140, Train loss: 0.18 Train acc: 0.908\n","Epoch:141, Train loss: 0.17 Train acc: 0.908\n","Epoch:142, Train loss: 0.17 Train acc: 0.908\n","Epoch:143, Train loss: 0.17 Train acc: 0.908\n","Epoch:144, Train loss: 0.17 Train acc: 0.908\n","Epoch:145, Train loss: 0.17 Train acc: 0.908\n","Epoch:146, Train loss: 0.17 Train acc: 0.908\n","Epoch:147, Train loss: 0.17 Train acc: 0.908\n","Epoch:148, Train loss: 0.17 Train acc: 0.908\n","Epoch:149, Train loss: 0.17 Train acc: 0.917\n","Epoch:150, Train loss: 0.16 Train acc: 0.917\n","Epoch:151, Train loss: 0.16 Train acc: 0.917\n","Epoch:152, Train loss: 0.16 Train acc: 0.917\n","Epoch:153, Train loss: 0.16 Train acc: 0.917\n","Epoch:154, Train loss: 0.16 Train acc: 0.917\n","Epoch:155, Train loss: 0.16 Train acc: 0.917\n","Epoch:156, Train loss: 0.16 Train acc: 0.917\n","Epoch:157, Train loss: 0.16 Train acc: 0.917\n","Epoch:158, Train loss: 0.16 Train acc: 0.925\n","Epoch:159, Train loss: 0.16 Train acc: 0.925\n","Epoch:160, Train loss: 0.16 Train acc: 0.925\n","Epoch:161, Train loss: 0.15 Train acc: 0.925\n","Epoch:162, Train loss: 0.15 Train acc: 0.925\n","Epoch:163, Train loss: 0.15 Train acc: 0.925\n","Epoch:164, Train loss: 0.15 Train acc: 0.925\n","Epoch:165, Train loss: 0.15 Train acc: 0.925\n","Epoch:166, Train loss: 0.15 Train acc: 0.925\n","Epoch:167, Train loss: 0.15 Train acc: 0.925\n","Epoch:168, Train loss: 0.15 Train acc: 0.925\n","Epoch:169, Train loss: 0.15 Train acc: 0.925\n","Epoch:170, Train loss: 0.15 Train acc: 0.925\n","Epoch:171, Train loss: 0.15 Train acc: 0.925\n","Epoch:172, Train loss: 0.15 Train acc: 0.933\n","Epoch:173, Train loss: 0.15 Train acc: 0.925\n","Epoch:174, Train loss: 0.15 Train acc: 0.933\n","Epoch:175, Train loss: 0.14 Train acc: 0.933\n","Epoch:176, Train loss: 0.14 Train acc: 0.942\n","Epoch:177, Train loss: 0.14 Train acc: 0.942\n","Epoch:178, Train loss: 0.14 Train acc: 0.942\n","Epoch:179, Train loss: 0.14 Train acc: 0.942\n","Epoch:180, Train loss: 0.14 Train acc: 0.942\n","Epoch:181, Train loss: 0.14 Train acc: 0.942\n","Epoch:182, Train loss: 0.14 Train acc: 0.950\n","Epoch:183, Train loss: 0.14 Train acc: 0.950\n","Epoch:184, Train loss: 0.14 Train acc: 0.950\n","Epoch:185, Train loss: 0.14 Train acc: 0.950\n","Epoch:186, Train loss: 0.14 Train acc: 0.950\n","Epoch:187, Train loss: 0.14 Train acc: 0.950\n","Epoch:188, Train loss: 0.14 Train acc: 0.950\n","Epoch:189, Train loss: 0.14 Train acc: 0.950\n","Epoch:190, Train loss: 0.14 Train acc: 0.950\n","Epoch:191, Train loss: 0.14 Train acc: 0.950\n","Epoch:192, Train loss: 0.14 Train acc: 0.950\n","Epoch:193, Train loss: 0.14 Train acc: 0.950\n","Epoch:194, Train loss: 0.14 Train acc: 0.950\n","Epoch:195, Train loss: 0.14 Train acc: 0.950\n","Epoch:196, Train loss: 0.13 Train acc: 0.950\n","Epoch:197, Train loss: 0.13 Train acc: 0.950\n","Epoch:198, Train loss: 0.13 Train acc: 0.950\n","Epoch:199, Train loss: 0.13 Train acc: 0.950\n","Epoch:200, Train loss: 0.13 Train acc: 0.950\n","Epoch:201, Train loss: 0.13 Train acc: 0.950\n","Epoch:202, Train loss: 0.13 Train acc: 0.950\n","Epoch:203, Train loss: 0.13 Train acc: 0.950\n","Epoch:204, Train loss: 0.13 Train acc: 0.950\n","Epoch:205, Train loss: 0.13 Train acc: 0.950\n","Epoch:206, Train loss: 0.13 Train acc: 0.950\n","Epoch:207, Train loss: 0.13 Train acc: 0.950\n","Epoch:208, Train loss: 0.13 Train acc: 0.950\n","Epoch:209, Train loss: 0.13 Train acc: 0.950\n","Epoch:210, Train loss: 0.13 Train acc: 0.950\n","Epoch:211, Train loss: 0.13 Train acc: 0.950\n","Epoch:212, Train loss: 0.13 Train acc: 0.950\n","Epoch:213, Train loss: 0.13 Train acc: 0.950\n","Epoch:214, Train loss: 0.13 Train acc: 0.950\n","Epoch:215, Train loss: 0.13 Train acc: 0.950\n","Epoch:216, Train loss: 0.13 Train acc: 0.950\n","Epoch:217, Train loss: 0.13 Train acc: 0.950\n","Epoch:218, Train loss: 0.13 Train acc: 0.950\n","Epoch:219, Train loss: 0.13 Train acc: 0.950\n","Epoch:220, Train loss: 0.13 Train acc: 0.950\n","Epoch:221, Train loss: 0.13 Train acc: 0.950\n","Epoch:222, Train loss: 0.13 Train acc: 0.950\n","Epoch:223, Train loss: 0.13 Train acc: 0.950\n","Epoch:224, Train loss: 0.13 Train acc: 0.950\n","Epoch:225, Train loss: 0.13 Train acc: 0.950\n","Epoch:226, Train loss: 0.13 Train acc: 0.950\n","Epoch:227, Train loss: 0.13 Train acc: 0.950\n","Epoch:228, Train loss: 0.13 Train acc: 0.950\n","Epoch:229, Train loss: 0.13 Train acc: 0.950\n","Epoch:230, Train loss: 0.13 Train acc: 0.950\n","Epoch:231, Train loss: 0.13 Train acc: 0.950\n","Epoch:232, Train loss: 0.13 Train acc: 0.950\n","Epoch:233, Train loss: 0.13 Train acc: 0.950\n","Epoch:234, Train loss: 0.13 Train acc: 0.950\n","Epoch:235, Train loss: 0.13 Train acc: 0.950\n","Epoch:236, Train loss: 0.13 Train acc: 0.950\n","Epoch:237, Train loss: 0.13 Train acc: 0.950\n","Epoch:238, Train loss: 0.13 Train acc: 0.950\n","Epoch:239, Train loss: 0.13 Train acc: 0.950\n","Epoch:240, Train loss: 0.13 Train acc: 0.950\n","Epoch:241, Train loss: 0.12 Train acc: 0.950\n","Epoch:242, Train loss: 0.12 Train acc: 0.950\n","Epoch:243, Train loss: 0.12 Train acc: 0.950\n","Epoch:244, Train loss: 0.12 Train acc: 0.950\n","Epoch:245, Train loss: 0.12 Train acc: 0.950\n","Epoch:246, Train loss: 0.12 Train acc: 0.950\n","Epoch:247, Train loss: 0.12 Train acc: 0.950\n","Epoch:248, Train loss: 0.12 Train acc: 0.950\n","Epoch:249, Train loss: 0.12 Train acc: 0.950\n","Epoch:250, Train loss: 0.12 Train acc: 0.950\n","Epoch:251, Train loss: 0.12 Train acc: 0.950\n","Epoch:252, Train loss: 0.12 Train acc: 0.950\n","Epoch:253, Train loss: 0.12 Train acc: 0.950\n","Epoch:254, Train loss: 0.12 Train acc: 0.950\n","Epoch:255, Train loss: 0.12 Train acc: 0.950\n","Epoch:256, Train loss: 0.12 Train acc: 0.950\n","Epoch:257, Train loss: 0.12 Train acc: 0.950\n","Epoch:258, Train loss: 0.12 Train acc: 0.950\n","Epoch:259, Train loss: 0.12 Train acc: 0.950\n","Epoch:260, Train loss: 0.12 Train acc: 0.950\n","Epoch:261, Train loss: 0.12 Train acc: 0.950\n","Epoch:262, Train loss: 0.12 Train acc: 0.950\n","Epoch:263, Train loss: 0.12 Train acc: 0.950\n","Epoch:264, Train loss: 0.12 Train acc: 0.950\n","Epoch:265, Train loss: 0.12 Train acc: 0.950\n","Epoch:266, Train loss: 0.12 Train acc: 0.950\n","Epoch:267, Train loss: 0.12 Train acc: 0.950\n","Epoch:268, Train loss: 0.12 Train acc: 0.950\n","Epoch:269, Train loss: 0.12 Train acc: 0.950\n","Epoch:270, Train loss: 0.12 Train acc: 0.950\n","Epoch:271, Train loss: 0.12 Train acc: 0.950\n","Epoch:272, Train loss: 0.12 Train acc: 0.950\n","Epoch:273, Train loss: 0.12 Train acc: 0.950\n","Epoch:274, Train loss: 0.12 Train acc: 0.950\n","Epoch:275, Train loss: 0.12 Train acc: 0.950\n","Epoch:276, Train loss: 0.12 Train acc: 0.950\n","Epoch:277, Train loss: 0.12 Train acc: 0.950\n","Epoch:278, Train loss: 0.12 Train acc: 0.967\n","Epoch:279, Train loss: 0.12 Train acc: 0.967\n","Epoch:280, Train loss: 0.12 Train acc: 0.967\n","Epoch:281, Train loss: 0.12 Train acc: 0.967\n","Epoch:282, Train loss: 0.12 Train acc: 0.967\n","Epoch:283, Train loss: 0.12 Train acc: 0.967\n","Epoch:284, Train loss: 0.12 Train acc: 0.967\n","Epoch:285, Train loss: 0.12 Train acc: 0.967\n","Epoch:286, Train loss: 0.12 Train acc: 0.967\n","Epoch:287, Train loss: 0.12 Train acc: 0.967\n","Epoch:288, Train loss: 0.12 Train acc: 0.967\n","Epoch:289, Train loss: 0.12 Train acc: 0.967\n","Epoch:290, Train loss: 0.12 Train acc: 0.967\n","Epoch:291, Train loss: 0.12 Train acc: 0.967\n","Epoch:292, Train loss: 0.12 Train acc: 0.967\n","Epoch:293, Train loss: 0.12 Train acc: 0.967\n","Epoch:294, Train loss: 0.12 Train acc: 0.967\n","Epoch:295, Train loss: 0.12 Train acc: 0.967\n","Epoch:296, Train loss: 0.12 Train acc: 0.967\n","Epoch:297, Train loss: 0.11 Train acc: 0.967\n","Epoch:298, Train loss: 0.11 Train acc: 0.967\n","Epoch:299, Train loss: 0.11 Train acc: 0.967\n","Epoch:300, Train loss: 0.11 Train acc: 0.967\n","Epoch:301, Train loss: 0.11 Train acc: 0.967\n","Epoch:302, Train loss: 0.11 Train acc: 0.967\n","Epoch:303, Train loss: 0.11 Train acc: 0.967\n","Epoch:304, Train loss: 0.11 Train acc: 0.967\n","Epoch:305, Train loss: 0.11 Train acc: 0.967\n","Epoch:306, Train loss: 0.11 Train acc: 0.967\n","Epoch:307, Train loss: 0.11 Train acc: 0.967\n","Epoch:308, Train loss: 0.11 Train acc: 0.967\n","Epoch:309, Train loss: 0.11 Train acc: 0.967\n","Epoch:310, Train loss: 0.11 Train acc: 0.967\n","Epoch:311, Train loss: 0.11 Train acc: 0.967\n","Epoch:312, Train loss: 0.11 Train acc: 0.967\n","Epoch:313, Train loss: 0.11 Train acc: 0.967\n","Epoch:314, Train loss: 0.11 Train acc: 0.967\n","Epoch:315, Train loss: 0.11 Train acc: 0.967\n","Epoch:316, Train loss: 0.11 Train acc: 0.967\n","Epoch:317, Train loss: 0.11 Train acc: 0.967\n","Epoch:318, Train loss: 0.11 Train acc: 0.967\n","Epoch:319, Train loss: 0.11 Train acc: 0.967\n","Epoch:320, Train loss: 0.11 Train acc: 0.967\n","Epoch:321, Train loss: 0.11 Train acc: 0.967\n","Epoch:322, Train loss: 0.11 Train acc: 0.967\n","Epoch:323, Train loss: 0.11 Train acc: 0.967\n","Epoch:324, Train loss: 0.11 Train acc: 0.967\n","Epoch:325, Train loss: 0.11 Train acc: 0.967\n","Epoch:326, Train loss: 0.11 Train acc: 0.967\n","Epoch:327, Train loss: 0.11 Train acc: 0.967\n","Epoch:328, Train loss: 0.11 Train acc: 0.967\n","Epoch:329, Train loss: 0.11 Train acc: 0.967\n","Epoch:330, Train loss: 0.11 Train acc: 0.967\n","Epoch:331, Train loss: 0.11 Train acc: 0.967\n","Epoch:332, Train loss: 0.11 Train acc: 0.967\n","Epoch:333, Train loss: 0.11 Train acc: 0.967\n","Epoch:334, Train loss: 0.11 Train acc: 0.967\n","Epoch:335, Train loss: 0.11 Train acc: 0.967\n","Epoch:336, Train loss: 0.11 Train acc: 0.967\n","Epoch:337, Train loss: 0.11 Train acc: 0.967\n","Epoch:338, Train loss: 0.11 Train acc: 0.967\n","Epoch:339, Train loss: 0.11 Train acc: 0.967\n","Epoch:340, Train loss: 0.11 Train acc: 0.967\n","Epoch:341, Train loss: 0.11 Train acc: 0.967\n","Epoch:342, Train loss: 0.11 Train acc: 0.967\n","Epoch:343, Train loss: 0.11 Train acc: 0.967\n","Epoch:344, Train loss: 0.11 Train acc: 0.967\n","Epoch:345, Train loss: 0.11 Train acc: 0.967\n","Epoch:346, Train loss: 0.11 Train acc: 0.967\n","Epoch:347, Train loss: 0.11 Train acc: 0.967\n","Epoch:348, Train loss: 0.11 Train acc: 0.967\n","Epoch:349, Train loss: 0.11 Train acc: 0.967\n","Epoch:350, Train loss: 0.11 Train acc: 0.967\n","Epoch:351, Train loss: 0.10 Train acc: 0.967\n","Epoch:352, Train loss: 0.10 Train acc: 0.967\n","Epoch:353, Train loss: 0.10 Train acc: 0.967\n","Epoch:354, Train loss: 0.10 Train acc: 0.967\n","Epoch:355, Train loss: 0.10 Train acc: 0.967\n","Epoch:356, Train loss: 0.10 Train acc: 0.967\n","Epoch:357, Train loss: 0.10 Train acc: 0.967\n","Epoch:358, Train loss: 0.10 Train acc: 0.967\n","Epoch:359, Train loss: 0.10 Train acc: 0.967\n","Epoch:360, Train loss: 0.10 Train acc: 0.967\n","Epoch:361, Train loss: 0.10 Train acc: 0.967\n","Epoch:362, Train loss: 0.10 Train acc: 0.967\n","Epoch:363, Train loss: 0.10 Train acc: 0.967\n","Epoch:364, Train loss: 0.10 Train acc: 0.967\n","Epoch:365, Train loss: 0.10 Train acc: 0.967\n","Epoch:366, Train loss: 0.10 Train acc: 0.967\n","Epoch:367, Train loss: 0.10 Train acc: 0.967\n","Epoch:368, Train loss: 0.10 Train acc: 0.967\n","Epoch:369, Train loss: 0.10 Train acc: 0.967\n","Epoch:370, Train loss: 0.10 Train acc: 0.967\n","Epoch:371, Train loss: 0.10 Train acc: 0.967\n","Epoch:372, Train loss: 0.10 Train acc: 0.967\n","Epoch:373, Train loss: 0.10 Train acc: 0.967\n","Epoch:374, Train loss: 0.10 Train acc: 0.967\n","Epoch:375, Train loss: 0.10 Train acc: 0.967\n","Epoch:376, Train loss: 0.10 Train acc: 0.967\n","Epoch:377, Train loss: 0.10 Train acc: 0.967\n","Epoch:378, Train loss: 0.10 Train acc: 0.967\n","Epoch:379, Train loss: 0.10 Train acc: 0.967\n","Epoch:380, Train loss: 0.10 Train acc: 0.967\n","Epoch:381, Train loss: 0.10 Train acc: 0.967\n","Epoch:382, Train loss: 0.10 Train acc: 0.967\n","Epoch:383, Train loss: 0.10 Train acc: 0.967\n","Epoch:384, Train loss: 0.10 Train acc: 0.967\n","Epoch:385, Train loss: 0.10 Train acc: 0.967\n","Epoch:386, Train loss: 0.10 Train acc: 0.967\n","Epoch:387, Train loss: 0.10 Train acc: 0.967\n","Epoch:388, Train loss: 0.10 Train acc: 0.967\n","Epoch:389, Train loss: 0.10 Train acc: 0.967\n","Epoch:390, Train loss: 0.10 Train acc: 0.967\n","Epoch:391, Train loss: 0.10 Train acc: 0.967\n","Epoch:392, Train loss: 0.10 Train acc: 0.967\n","Epoch:393, Train loss: 0.10 Train acc: 0.967\n","Epoch:394, Train loss: 0.10 Train acc: 0.967\n","Epoch:395, Train loss: 0.10 Train acc: 0.967\n","Epoch:396, Train loss: 0.10 Train acc: 0.967\n","Epoch:397, Train loss: 0.10 Train acc: 0.967\n","Epoch:398, Train loss: 0.10 Train acc: 0.967\n","Epoch:399, Train loss: 0.10 Train acc: 0.967\n","Epoch:400, Train loss: 0.10 Train acc: 0.967\n","Epoch:401, Train loss: 0.10 Train acc: 0.967\n","Epoch:402, Train loss: 0.10 Train acc: 0.967\n","Epoch:403, Train loss: 0.10 Train acc: 0.967\n","Epoch:404, Train loss: 0.10 Train acc: 0.967\n","Epoch:405, Train loss: 0.10 Train acc: 0.967\n","Epoch:406, Train loss: 0.10 Train acc: 0.958\n","Epoch:407, Train loss: 0.10 Train acc: 0.967\n","Epoch:408, Train loss: 0.10 Train acc: 0.967\n","Epoch:409, Train loss: 0.10 Train acc: 0.967\n","Epoch:410, Train loss: 0.10 Train acc: 0.967\n","Epoch:411, Train loss: 0.10 Train acc: 0.967\n","Epoch:412, Train loss: 0.10 Train acc: 0.967\n","Epoch:413, Train loss: 0.10 Train acc: 0.967\n","Epoch:414, Train loss: 0.10 Train acc: 0.967\n","Epoch:415, Train loss: 0.10 Train acc: 0.967\n","Epoch:416, Train loss: 0.10 Train acc: 0.967\n","Epoch:417, Train loss: 0.10 Train acc: 0.967\n","Epoch:418, Train loss: 0.10 Train acc: 0.967\n","Epoch:419, Train loss: 0.10 Train acc: 0.967\n","Epoch:420, Train loss: 0.10 Train acc: 0.967\n","Epoch:421, Train loss: 0.10 Train acc: 0.967\n","Epoch:422, Train loss: 0.10 Train acc: 0.967\n","Epoch:423, Train loss: 0.10 Train acc: 0.967\n","Epoch:424, Train loss: 0.10 Train acc: 0.967\n","Epoch:425, Train loss: 0.10 Train acc: 0.967\n","Epoch:426, Train loss: 0.10 Train acc: 0.967\n","Epoch:427, Train loss: 0.10 Train acc: 0.967\n","Epoch:428, Train loss: 0.10 Train acc: 0.967\n","Epoch:429, Train loss: 0.10 Train acc: 0.967\n","Epoch:430, Train loss: 0.10 Train acc: 0.967\n","Epoch:431, Train loss: 0.10 Train acc: 0.967\n","Epoch:432, Train loss: 0.10 Train acc: 0.967\n","Epoch:433, Train loss: 0.10 Train acc: 0.958\n","Epoch:434, Train loss: 0.10 Train acc: 0.967\n","Epoch:435, Train loss: 0.10 Train acc: 0.958\n","Epoch:436, Train loss: 0.10 Train acc: 0.967\n","Epoch:437, Train loss: 0.09 Train acc: 0.967\n","Epoch:438, Train loss: 0.09 Train acc: 0.967\n","Epoch:439, Train loss: 0.09 Train acc: 0.967\n","Epoch:440, Train loss: 0.09 Train acc: 0.967\n","Epoch:441, Train loss: 0.09 Train acc: 0.958\n","Epoch:442, Train loss: 0.09 Train acc: 0.967\n","Epoch:443, Train loss: 0.09 Train acc: 0.967\n","Epoch:444, Train loss: 0.09 Train acc: 0.967\n","Epoch:445, Train loss: 0.09 Train acc: 0.958\n","Epoch:446, Train loss: 0.09 Train acc: 0.967\n","Epoch:447, Train loss: 0.09 Train acc: 0.958\n","Epoch:448, Train loss: 0.09 Train acc: 0.967\n","Epoch:449, Train loss: 0.09 Train acc: 0.958\n","Epoch:450, Train loss: 0.09 Train acc: 0.967\n","Epoch:451, Train loss: 0.09 Train acc: 0.967\n","Epoch:452, Train loss: 0.09 Train acc: 0.967\n","Epoch:453, Train loss: 0.09 Train acc: 0.958\n","Epoch:454, Train loss: 0.09 Train acc: 0.958\n","Epoch:455, Train loss: 0.09 Train acc: 0.967\n","Epoch:456, Train loss: 0.09 Train acc: 0.967\n","Epoch:457, Train loss: 0.09 Train acc: 0.967\n","Epoch:458, Train loss: 0.09 Train acc: 0.967\n","Epoch:459, Train loss: 0.09 Train acc: 0.967\n","Epoch:460, Train loss: 0.09 Train acc: 0.958\n","Epoch:461, Train loss: 0.09 Train acc: 0.958\n","Epoch:462, Train loss: 0.09 Train acc: 0.958\n","Epoch:463, Train loss: 0.09 Train acc: 0.967\n","Epoch:464, Train loss: 0.09 Train acc: 0.958\n","Epoch:465, Train loss: 0.09 Train acc: 0.958\n","Epoch:466, Train loss: 0.09 Train acc: 0.967\n","Epoch:467, Train loss: 0.09 Train acc: 0.958\n","Epoch:468, Train loss: 0.09 Train acc: 0.967\n","Epoch:469, Train loss: 0.09 Train acc: 0.967\n","Epoch:470, Train loss: 0.09 Train acc: 0.958\n","Epoch:471, Train loss: 0.09 Train acc: 0.958\n","Epoch:472, Train loss: 0.09 Train acc: 0.958\n","Epoch:473, Train loss: 0.09 Train acc: 0.967\n","Epoch:474, Train loss: 0.09 Train acc: 0.967\n","Epoch:475, Train loss: 0.09 Train acc: 0.958\n","Epoch:476, Train loss: 0.09 Train acc: 0.967\n","Epoch:477, Train loss: 0.09 Train acc: 0.958\n","Epoch:478, Train loss: 0.09 Train acc: 0.967\n","Epoch:479, Train loss: 0.09 Train acc: 0.958\n","Epoch:480, Train loss: 0.09 Train acc: 0.958\n","Epoch:481, Train loss: 0.09 Train acc: 0.958\n","Epoch:482, Train loss: 0.09 Train acc: 0.958\n","Epoch:483, Train loss: 0.09 Train acc: 0.958\n","Epoch:484, Train loss: 0.09 Train acc: 0.958\n","Epoch:485, Train loss: 0.09 Train acc: 0.958\n","Epoch:486, Train loss: 0.09 Train acc: 0.958\n","Epoch:487, Train loss: 0.09 Train acc: 0.958\n","Epoch:488, Train loss: 0.09 Train acc: 0.967\n","Epoch:489, Train loss: 0.09 Train acc: 0.958\n","Epoch:490, Train loss: 0.09 Train acc: 0.958\n","Epoch:491, Train loss: 0.09 Train acc: 0.958\n","Epoch:492, Train loss: 0.09 Train acc: 0.958\n","Epoch:493, Train loss: 0.09 Train acc: 0.958\n","Epoch:494, Train loss: 0.09 Train acc: 0.958\n","Epoch:495, Train loss: 0.09 Train acc: 0.958\n","Epoch:496, Train loss: 0.09 Train acc: 0.958\n","Epoch:497, Train loss: 0.09 Train acc: 0.958\n","Epoch:498, Train loss: 0.09 Train acc: 0.958\n","Epoch:499, Train loss: 0.09 Train acc: 0.958\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","\n","Test Accuracy: 0.966667\n","\n","[0.00016138732, 0.37580565]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9666666666666667"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x2XL_CbhIdrV"},"outputs":[],"source":["def func_modified3(regularizer_rate_0,regularizer_rate_1,num_layers_0, epochs, batch_size, num_classes, sensor_sizes, dep, xvals, yvals, reduction):\n","\n","  from numpy.linalg import norm\n","  import keras\n","  from keras.layers import Activation, Dense\n","  import numpy as np\n","  import pandas as pd\n","  import tensorflow as tf\n","  from sklearn.metrics import accuracy_score\n","  from tensorflow.keras.layers import Dense, Activation\n","  import tensorflow.compat.v1 as tf\n","  tf.disable_v2_behavior()\n","  from sklearn.model_selection import train_test_split\n","\n","  xvals_train, xvals_test,yvals_train, yvals_test = train_test_split(xvals,yvals,random_state=None, test_size=0.2,  shuffle=True)\n","                                                                     \n","  starter_learning_rate = 0.001\n","  num_features=sum(sensor_sizes)\n","  nrow=len(yvals_train)\n","  num_output=num_classes\n","\n","  input_X = tf.placeholder('float32',shape =(None,num_features),name=\"input_X\")\n","  input_y = tf.placeholder('float32',shape = (None,num_classes),name='input_Y')\n","\n","  s=tf.compat.v1.InteractiveSession()\n","  ## Weights initialized by random normal function with std_dev = 1/sqrt(number of input features)\n","  weights_0 = tf.Variable(tf.random.normal([num_features,num_layers_0], stddev=(1/tf.sqrt(float(num_features)))))\n","  bias_0 = tf.Variable(tf.random.normal([num_layers_0]))\n","  weights_1 = tf.Variable(tf.random.normal([num_layers_0,num_output], stddev=(1/tf.sqrt(float(num_layers_0)))))\n","  bias_1 = tf.Variable(tf.random.normal([num_output]))\n","\n","  ## Initializing weigths and biases\n","  hidden_output_0 = tf.nn.relu(tf.matmul(input_X,weights_0)+bias_0)\n","  predicted_y = tf.sigmoid(tf.matmul(hidden_output_0,weights_1) + bias_1)\n","\n","  ##calculate penalty terms\n","  series = pd.Series(sensor_sizes)\n","  cumsum = series.cumsum()\n","  penalty=(tf.reduce_sum(tf.square(weights_0[0:sensor_sizes[0]])))**0.5/sensor_sizes[0]\n","  for i in range(len(sensor_sizes)-1):\n","    penalty=penalty+((tf.reduce_sum(tf.square(weights_0[cumsum[i]:cumsum[i+1]])))**0.5)/sensor_sizes[i+1]\n","\n","  cumsum =[0]+ list(series.cumsum())\n","  redund=0\n","  r_mat=np.array(xvals_train.corr())\n","  rsq_mat=[[elem*elem for elem in inner] for inner in r_mat]\n","  rsq_mat=pd.DataFrame(rsq_mat)\n","  for i in range(len(sensor_sizes)):\n","    for j in range(len(sensor_sizes)):\n","      if j!=i:\n","        redund=redund+dep(rsq_mat,sensor_sizes,i+1,j+1)*((tf.reduce_sum(tf.square(weights_0[cumsum[j]:cumsum[j+1]])))*(tf.reduce_sum(tf.square(weights_0[cumsum[i]:cumsum[i+1]])))**0.5)/(sensor_sizes[i]*sensor_sizes[j])\n","\n","  if len(sensor_sizes)>1:\n","    redund=redund/(len(sensor_sizes)*(len(sensor_sizes)-1))\n","\n","  loss = tf.reduce_mean(tf.square(predicted_y-tf.convert_to_tensor(yvals_train, dtype=tf.float32))) + regularizer_rate_0*redund/num_layers_0**2 + regularizer_rate_1*penalty/num_layers_0 \n","\n","\n","  ## Variable learning rate\n","  learning_rate = tf.train.exponential_decay(starter_learning_rate, 0, 5, 0.85, staircase=True)\n","  ## Adam optimzer for finding the right weight\n","  optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,var_list=[weights_0,weights_1,\n","                                                                         bias_0,bias_1])    \n","  ## Metrics definition\n","  correct_prediction = tf.equal(tf.argmax(yvals_train,1), tf.argmax(predicted_y,1))\n","  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","  training_accuracy = []\n","  training_loss = []\n","  testing_accuracy = []\n","  #s.run(tf.initialize_all_variables)\n","  s.run(tf.compat.v1.global_variables_initializer())\n","  #x=func_modified(regularizer_rate_0,regularizer_rate_1,num_layers_0, epochs, batch_size, num_classes, sensor_sizes, dep)\n","  #weights_0=x[0]\n","  #weights_1=x[1]\n","  #bias_0=x[2]\n","  #bias_1=x[3]\n","  for epoch in range(epochs):    \n","    arr = np.arange(nrow)\n","    np.random.shuffle(arr)\n","    for index in range(0,nrow,batch_size):\n","        s.run(optimizer, {input_X: xvals_train,\n","                          input_y: yvals_train})\n","        \n","    training_accuracy.append(s.run(accuracy, feed_dict= {input_X:xvals_train, \n","                                                         input_y: yvals_train}))\n","    training_loss.append(s.run(loss, {input_X: xvals_train, \n","                                      input_y: yvals_train}))\n","    #print(\"Epoch:{0}, Train loss: {1:.2f} Train acc: {2:.3f}\".format(epoch,training_loss[epoch],training_accuracy[epoch]))\n","   \n","  ## Evaluation of test data\n","  #for i in range(len(xvals_test)):\n","    #print('Actual:', yvals_test[i], 'Predicted:', np.rint(s.run(predicted_y, feed_dict={input_X: [xvals_test.iloc[i]]})))\n","\n","  y_pred = np.rint(s.run(predicted_y, feed_dict={input_X: xvals_test}))\n","\n","  testacc = accuracy_score(yvals_test, y_pred)\n"," \n","  print(\"\\nTest Accuracy: {0:f}\\n\".format(testacc))\n","\n","  w0=weights_0.eval()\n","  w=[]\n","  #w.append(norm(w0[0:sensor_sizes[0]],2))\n","  for i in range(len(sensor_sizes)):\n","    w.append(norm(w0[cumsum[i]:cumsum[i+1]],2))\n","  #Feature selection\n","  if reduction==True:\n","    v=[i for i,x in enumerate(w) if x > 0.1*max(w)]\n","    selected=[]\n","    for i in v:\n","      selected.append(xvals.iloc[:,range(cumsum[i],cumsum[i+1])])\n","  \n","    xvals_reduced=pd.concat(selected,ignore_index=True, axis=1)\n","    #print(xvals_reduced)\n","    acc=0\n","    sensor_sizes_red=[sensor_sizes[i] for i in v]\n","    for i in range(10):\n","      acc=acc+func_modified3(regularizer_rate_0,regularizer_rate_1,num_layers_0, epochs, batch_size, num_classes, sensor_sizes_red,dep_cor,xvals_reduced,yvals,reduction=False)[0]\n","    return([acc/10,len(sensor_sizes_red),v])\n","  else:\n","    return([testacc,len(sensor_sizes)])"]},{"cell_type":"code","source":["func_modified3(1,1,10,500,10,3,[2,2],dep_cor,xvals,yvals,False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9my0smAoBTQU","executionInfo":{"status":"ok","timestamp":1675782555676,"user_tz":-330,"elapsed":12878,"user":{"displayName":"Aytijhya Saha","userId":"15087240692289809888"}},"outputId":"95f3cc12-459b-46a2-ab26-592dae8db00c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.0, 2]"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","execution_count":55,"metadata":{"id":"5FGye0M_X1Qk","executionInfo":{"status":"ok","timestamp":1675794521211,"user_tz":-330,"elapsed":761,"user":{"displayName":"Aytijhya Saha","userId":"15087240692289809888"}}},"outputs":[],"source":["def func_modified3(regularizer_rate_0,regularizer_rate_1,num_layers_0, epochs, batch_size, num_classes, sensor_sizes, dep, xvals, yvals, reduction):\n","\n","  from numpy.linalg import norm\n","  import keras\n","  from keras.layers import Activation, Dense\n","  import numpy as np\n","  import pandas as pd\n","  import tensorflow as tf\n","  from sklearn.metrics import accuracy_score\n","  from tensorflow.keras.layers import Dense, Activation\n","  import tensorflow.compat.v1 as tf\n","  tf.disable_v2_behavior()\n","  from sklearn.model_selection import train_test_split\n","  \n","\n","  xvals_train, xvals_test,yvals_train, yvals_test = train_test_split(xvals,yvals,random_state=None, test_size=0.2,  shuffle=True)\n","                                                                     \n","  starter_learning_rate = 0.001\n","  num_features=sum(sensor_sizes)\n","  nrow=len(yvals_train)\n","  num_output=num_classes\n","\n","  input_X = tf.placeholder('float32',shape =(None,num_features),name=\"input_X\")\n","  input_y = tf.placeholder('float32',shape = (None,num_classes),name='input_Y')\n","\n","  s=tf.compat.v1.InteractiveSession()\n","  ## Weights initialized by random normal function with std_dev = 1/sqrt(number of input features)\n","  weights_0 = tf.Variable(tf.random.normal([num_features,num_layers_0], stddev=(1/tf.sqrt(float(num_features)))))\n","  bias_0 = tf.Variable(tf.random.normal([num_layers_0]))\n","  weights_1 = tf.Variable(tf.random.normal([num_layers_0,num_output], stddev=(1/tf.sqrt(float(num_layers_0)))))\n","  bias_1 = tf.Variable(tf.random.normal([num_output]))\n","\n","  ## Initializing weigths and biases\n","  hidden_output_0 = tf.nn.relu(tf.matmul(input_X,weights_0)+bias_0)\n","  predicted_y = tf.sigmoid(tf.matmul(hidden_output_0,weights_1) + bias_1)\n","\n","  ##calculate penalty terms\n","  series = pd.Series(sensor_sizes)\n","  cumsum = series.cumsum()\n","  penalty=(tf.reduce_sum(tf.square(weights_0[0:sensor_sizes[0]])))**0.5/sensor_sizes[0]\n","  for i in range(len(sensor_sizes)-1):\n","    penalty=penalty+((tf.reduce_sum(tf.square(weights_0[cumsum[i]:cumsum[i+1]])))**0.5)/sensor_sizes[i+1]\n","\n","  cumsum =[0]+ list(series.cumsum())\n","  redund=0\n","  r_mat=np.array(xvals_train.corr())\n","  rsq_mat=[[elem*elem for elem in inner] for inner in r_mat]\n","  rsq_mat=pd.DataFrame(rsq_mat)\n","  for i in range(len(sensor_sizes)):\n","    for j in range(len(sensor_sizes)):\n","      if j!=i:\n","        redund=redund+dep(rsq_mat,sensor_sizes,i+1,j+1)*((tf.reduce_sum(tf.square(weights_0[cumsum[j]:cumsum[j+1]])))*(tf.reduce_sum(tf.square(weights_0[cumsum[i]:cumsum[i+1]])))**0.5)/(sensor_sizes[i]*sensor_sizes[j])\n","\n","  if len(sensor_sizes)>1:\n","    redund=redund/(len(sensor_sizes)*(len(sensor_sizes)-1))\n","\n","  loss = tf.reduce_mean(tf.square(predicted_y-tf.convert_to_tensor(yvals_train, dtype=tf.float32))) + regularizer_rate_0*redund/num_layers_0**2 + regularizer_rate_1*penalty/num_layers_0 \n","\n","\n","  ## Variable learning rate\n","  learning_rate = tf.train.exponential_decay(starter_learning_rate, 0, 5, 0.85, staircase=True)\n","  ## Adam optimzer for finding the right weight\n","  optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,var_list=[weights_0,weights_1,\n","                                                                         bias_0,bias_1])    \n","  ## Metrics definition\n","  correct_prediction = tf.equal(tf.argmax(yvals_train,1), tf.argmax(predicted_y,1))\n","  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","  training_accuracy = []\n","  training_loss = []\n","  testing_accuracy = []\n","  #s.run(tf.initialize_all_variables)\n","  s.run(tf.compat.v1.global_variables_initializer())\n","  w0=weights_0.eval()\n","  print(w0)\n","  x=func_modified(0,0,num_layers_0, epochs, batch_size, num_classes, sensor_sizes, dep)\n","  weights_0=x[0]\n","  weights_1=x[1]\n","  bias_0=x[2]\n","  bias_1=x[3]\n","  #w0=weights_0.eval()\n","  #print(w0)\n","  for epoch in range(epochs):    \n","    arr = np.arange(nrow)\n","    np.random.shuffle(arr)\n","    for index in range(0,nrow,batch_size):\n","        s.run(optimizer, {input_X: xvals_train,\n","                          input_y: yvals_train})\n","        \n","    training_accuracy.append(s.run(accuracy, feed_dict= {input_X:xvals_train, \n","                                                         input_y: yvals_train}))\n","    training_loss.append(s.run(loss, {input_X: xvals_train, \n","                                      input_y: yvals_train}))\n","    #print(\"Epoch:{0}, Train loss: {1:.2f} Train acc: {2:.3f}\".format(epoch,training_loss[epoch],training_accuracy[epoch]))\n","   \n","  ## Evaluation of test data\n","  #for i in range(len(xvals_test)):\n","    #print('Actual:', yvals_test[i], 'Predicted:', np.rint(s.run(predicted_y, feed_dict={input_X: [xvals_test.iloc[i]]})))\n","\n","  y_pred = np.rint(s.run(predicted_y, feed_dict={input_X: xvals_test}))\n","\n","  testacc = accuracy_score(yvals_test, y_pred)\n"," \n","  print(\"\\nTest Accuracy: {0:f}\\n\".format(testacc))\n","\n","  w0=weights_0.eval()\n","  w=[]\n","  \n","  print(w0)\n","  #w.append(norm(w0[0:sensor_sizes[0]],2))\n","  for i in range(len(sensor_sizes)):\n","    w.append(norm(w0[cumsum[i]:cumsum[i+1]],2))\n","  #Feature selection\n","  if reduction==True:\n","    v=[i for i,x in enumerate(w) if x > 0.1*max(w)]\n","    selected=[]\n","    for i in v:\n","      selected.append(xvals.iloc[:,range(cumsum[i],cumsum[i+1])])\n","  \n","    xvals_reduced=pd.concat(selected,ignore_index=True, axis=1)\n","    #print(xvals_reduced)\n","    acc=0\n","    sensor_sizes_red=[sensor_sizes[i] for i in v]\n","    for i in range(10):\n","      acc=acc+func_modified3(regularizer_rate_0,regularizer_rate_1,num_layers_0, epochs, batch_size, num_classes, sensor_sizes_red,dep_cor,xvals_reduced,yvals,reduction=False)[0]\n","    return([acc/10,len(sensor_sizes_red),v])\n","  else:\n","    return([testacc,len(sensor_sizes)])"]},{"cell_type":"code","source":["x=func_modified(1,1,10,100,10,3,[2,2],dep_cor)\n","\n","x[0]"],"metadata":{"id":"TT86IybVbkEE","executionInfo":{"status":"ok","timestamp":1675795055880,"user_tz":-330,"elapsed":5936,"user":{"displayName":"Aytijhya Saha","userId":"15087240692289809888"}},"outputId":"19a944be-04fc-4cbf-8654-a4802034233b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":58,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch:0, Train loss: 9.29 Train acc: 0.317\n","Epoch:1, Train loss: 8.93 Train acc: 0.317\n","Epoch:2, Train loss: 8.58 Train acc: 0.317\n","Epoch:3, Train loss: 8.25 Train acc: 0.317\n","Epoch:4, Train loss: 7.95 Train acc: 0.317\n","Epoch:5, Train loss: 7.67 Train acc: 0.300\n","Epoch:6, Train loss: 7.40 Train acc: 0.308\n","Epoch:7, Train loss: 7.16 Train acc: 0.367\n","Epoch:8, Train loss: 6.92 Train acc: 0.367\n","Epoch:9, Train loss: 6.70 Train acc: 0.450\n","Epoch:10, Train loss: 6.49 Train acc: 0.633\n","Epoch:11, Train loss: 6.28 Train acc: 0.675\n","Epoch:12, Train loss: 6.09 Train acc: 0.683\n","Epoch:13, Train loss: 5.91 Train acc: 0.683\n","Epoch:14, Train loss: 5.73 Train acc: 0.683\n","Epoch:15, Train loss: 5.56 Train acc: 0.683\n","Epoch:16, Train loss: 5.40 Train acc: 0.683\n","Epoch:17, Train loss: 5.25 Train acc: 0.683\n","Epoch:18, Train loss: 5.10 Train acc: 0.683\n","Epoch:19, Train loss: 4.96 Train acc: 0.683\n","Epoch:20, Train loss: 4.83 Train acc: 0.683\n","Epoch:21, Train loss: 4.70 Train acc: 0.683\n","Epoch:22, Train loss: 4.57 Train acc: 0.683\n","Epoch:23, Train loss: 4.45 Train acc: 0.683\n","Epoch:24, Train loss: 4.34 Train acc: 0.683\n","Epoch:25, Train loss: 4.23 Train acc: 0.683\n","Epoch:26, Train loss: 4.12 Train acc: 0.683\n","Epoch:27, Train loss: 4.02 Train acc: 0.683\n","Epoch:28, Train loss: 3.92 Train acc: 0.683\n","Epoch:29, Train loss: 3.83 Train acc: 0.683\n","Epoch:30, Train loss: 3.73 Train acc: 0.683\n","Epoch:31, Train loss: 3.65 Train acc: 0.683\n","Epoch:32, Train loss: 3.56 Train acc: 0.683\n","Epoch:33, Train loss: 3.48 Train acc: 0.683\n","Epoch:34, Train loss: 3.40 Train acc: 0.683\n","Epoch:35, Train loss: 3.32 Train acc: 0.683\n","Epoch:36, Train loss: 3.25 Train acc: 0.683\n","Epoch:37, Train loss: 3.17 Train acc: 0.700\n","Epoch:38, Train loss: 3.10 Train acc: 0.708\n","Epoch:39, Train loss: 3.03 Train acc: 0.708\n","Epoch:40, Train loss: 2.97 Train acc: 0.708\n","Epoch:41, Train loss: 2.90 Train acc: 0.708\n","Epoch:42, Train loss: 2.84 Train acc: 0.708\n","Epoch:43, Train loss: 2.78 Train acc: 0.708\n","Epoch:44, Train loss: 2.72 Train acc: 0.708\n","Epoch:45, Train loss: 2.66 Train acc: 0.708\n","Epoch:46, Train loss: 2.61 Train acc: 0.708\n","Epoch:47, Train loss: 2.55 Train acc: 0.708\n","Epoch:48, Train loss: 2.50 Train acc: 0.708\n","Epoch:49, Train loss: 2.45 Train acc: 0.717\n","Epoch:50, Train loss: 2.40 Train acc: 0.725\n","Epoch:51, Train loss: 2.35 Train acc: 0.725\n","Epoch:52, Train loss: 2.30 Train acc: 0.725\n","Epoch:53, Train loss: 2.25 Train acc: 0.725\n","Epoch:54, Train loss: 2.21 Train acc: 0.725\n","Epoch:55, Train loss: 2.16 Train acc: 0.725\n","Epoch:56, Train loss: 2.12 Train acc: 0.725\n","Epoch:57, Train loss: 2.07 Train acc: 0.733\n","Epoch:58, Train loss: 2.03 Train acc: 0.733\n","Epoch:59, Train loss: 1.99 Train acc: 0.717\n","Epoch:60, Train loss: 1.95 Train acc: 0.717\n","Epoch:61, Train loss: 1.91 Train acc: 0.717\n","Epoch:62, Train loss: 1.87 Train acc: 0.717\n","Epoch:63, Train loss: 1.84 Train acc: 0.717\n","Epoch:64, Train loss: 1.80 Train acc: 0.717\n","Epoch:65, Train loss: 1.77 Train acc: 0.717\n","Epoch:66, Train loss: 1.73 Train acc: 0.708\n","Epoch:67, Train loss: 1.70 Train acc: 0.708\n","Epoch:68, Train loss: 1.66 Train acc: 0.708\n","Epoch:69, Train loss: 1.63 Train acc: 0.708\n","Epoch:70, Train loss: 1.60 Train acc: 0.700\n","Epoch:71, Train loss: 1.57 Train acc: 0.700\n","Epoch:72, Train loss: 1.53 Train acc: 0.700\n","Epoch:73, Train loss: 1.50 Train acc: 0.700\n","Epoch:74, Train loss: 1.47 Train acc: 0.700\n","Epoch:75, Train loss: 1.44 Train acc: 0.700\n","Epoch:76, Train loss: 1.42 Train acc: 0.700\n","Epoch:77, Train loss: 1.39 Train acc: 0.683\n","Epoch:78, Train loss: 1.36 Train acc: 0.683\n","Epoch:79, Train loss: 1.33 Train acc: 0.683\n","Epoch:80, Train loss: 1.31 Train acc: 0.683\n","Epoch:81, Train loss: 1.28 Train acc: 0.683\n","Epoch:82, Train loss: 1.26 Train acc: 0.683\n","Epoch:83, Train loss: 1.23 Train acc: 0.683\n","Epoch:84, Train loss: 1.21 Train acc: 0.683\n","Epoch:85, Train loss: 1.18 Train acc: 0.683\n","Epoch:86, Train loss: 1.16 Train acc: 0.683\n","Epoch:87, Train loss: 1.13 Train acc: 0.683\n","Epoch:88, Train loss: 1.11 Train acc: 0.683\n","Epoch:89, Train loss: 1.09 Train acc: 0.683\n","Epoch:90, Train loss: 1.06 Train acc: 0.683\n","Epoch:91, Train loss: 1.04 Train acc: 0.683\n","Epoch:92, Train loss: 1.02 Train acc: 0.683\n","Epoch:93, Train loss: 1.00 Train acc: 0.683\n","Epoch:94, Train loss: 0.98 Train acc: 0.683\n","Epoch:95, Train loss: 0.96 Train acc: 0.683\n","Epoch:96, Train loss: 0.94 Train acc: 0.683\n","Epoch:97, Train loss: 0.92 Train acc: 0.683\n","Epoch:98, Train loss: 0.90 Train acc: 0.683\n","Epoch:99, Train loss: 0.88 Train acc: 0.683\n","Actual: [1. 0. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [1. 0. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [1. 0. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","30\n","30\n","\n","Test Accuracy: 0.166667\n","\n","[0.48703933, 0.18640013]\n"]},{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable_156:0' shape=(4, 10) dtype=float32_ref>"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33O3ez7-bUZ0"},"outputs":[],"source":["def func_modified4(regularizer_rate_0,regularizer_rate_1,num_layers_0, epochs, batch_size, num_classes, sensor_sizes, dep, xvals, yvals, reduction):\n","\n","  from numpy.linalg import norm\n","  import keras\n","  from keras.layers import Activation, Dense\n","  import numpy as np\n","  import pandas as pd\n","  import tensorflow as tf\n","  from sklearn.metrics import accuracy_score\n","  from tensorflow.keras.layers import Dense, Activation\n","  import tensorflow.compat.v1 as tf\n","  tf.disable_v2_behavior()\n","  from sklearn.model_selection import train_test_split\n","\n","  xvals_train, xvals_test,yvals_train, yvals_test = train_test_split(xvals,yvals,random_state=None, test_size=0.2,  shuffle=True)\n","                                                                     \n","  starter_learning_rate = 0.001\n","  num_features=sum(sensor_sizes)\n","  nrow=len(yvals_train)\n","  num_output=num_classes\n","\n","  input_X = tf.placeholder('float32',shape =(None,num_features),name=\"input_X\")\n","  input_y = tf.placeholder('float32',shape = (None,num_classes),name='input_Y')\n","\n","  s=tf.compat.v1.InteractiveSession()\n","  ## Weights initialized by random normal function with std_dev = 1/sqrt(number of input features)\n","  weights_0 = tf.Variable(tf.random.normal([num_features,num_layers_0], stddev=(1/tf.sqrt(float(num_features)))))\n","  bias_0 = tf.Variable(tf.random.normal([num_layers_0]))\n","  weights_1 = tf.Variable(tf.random.normal([num_layers_0,num_output], stddev=(1/tf.sqrt(float(num_layers_0)))))\n","  bias_1 = tf.Variable(tf.random.normal([num_output]))\n","\n","  ## Initializing weigths and biases\n","  hidden_output_0 = tf.nn.relu(tf.matmul(input_X,weights_0)+bias_0)\n","  predicted_y = tf.sigmoid(tf.matmul(hidden_output_0,weights_1) + bias_1)\n","\n","  ##calculate penalty terms\n","  series = pd.Series(sensor_sizes)\n","  cumsum = series.cumsum()\n","  penalty=(tf.reduce_sum(tf.square(weights_0[0:sensor_sizes[0]])))**0.5/sensor_sizes[0]\n","  for i in range(len(sensor_sizes)-1):\n","    penalty=penalty+((tf.reduce_sum(tf.square(weights_0[cumsum[i]:cumsum[i+1]])))**0.5)/sensor_sizes[i+1]\n","\n","  cumsum =[0]+ list(series.cumsum())\n","  redund=0\n","  r_mat=np.array(xvals_train.corr())\n","  rsq_mat=[[elem*elem for elem in inner] for inner in r_mat]\n","  rsq_mat=pd.DataFrame(rsq_mat)\n","  for i in range(len(sensor_sizes)):\n","    for j in range(len(sensor_sizes)):\n","      if j!=i:\n","        redund=redund+dep(rsq_mat,sensor_sizes,i+1,j+1)*((tf.reduce_sum(tf.square(weights_0[cumsum[j]:cumsum[j+1]])))*(tf.reduce_sum(tf.square(weights_0[cumsum[i]:cumsum[i+1]])))**0.5)/(sensor_sizes[i]*sensor_sizes[j])\n","\n","  if len(sensor_sizes)>1:\n","    redund=redund/(len(sensor_sizes)*(len(sensor_sizes)-1))\n","\n","  loss = tf.reduce_mean(tf.square(predicted_y-tf.convert_to_tensor(yvals_train, dtype=tf.float32))) + regularizer_rate_0*redund/num_layers_0**2 + regularizer_rate_1*penalty/num_layers_0 \n","\n","\n","  ## Variable learning rate\n","  learning_rate = tf.train.exponential_decay(starter_learning_rate, 0, 5, 0.85, staircase=True)\n","  ## Adam optimzer for finding the right weight\n","  optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,var_list=[weights_0,weights_1,\n","                                                                         bias_0,bias_1])    \n","  ## Metrics definition\n","  correct_prediction = tf.equal(tf.argmax(yvals_train,1), tf.argmax(predicted_y,1))\n","  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","  training_accuracy = []\n","  training_loss = []\n","  testing_accuracy = []\n","  #s.run(tf.initialize_all_variables)\n","  s.run(tf.compat.v1.global_variables_initializer())\n","  for epoch in range(epochs):    \n","    arr = np.arange(nrow)\n","    np.random.shuffle(arr)\n","    for index in range(0,nrow,batch_size):\n","        s.run(optimizer, {input_X: xvals_train,\n","                          input_y: yvals_train})\n","        \n","    training_accuracy.append(s.run(accuracy, feed_dict= {input_X:xvals_train, \n","                                                         input_y: yvals_train}))\n","    training_loss.append(s.run(loss, {input_X: xvals_train, \n","                                      input_y: yvals_train}))\n","    print(\"Epoch:{0}, Train loss: {1:.2f} Train acc: {2:.3f}\".format(epoch,\n","                                                                    training_loss[epoch],\n","                                                                    training_accuracy[epoch]))\n","   \n","  ## Evaluation of test data\n","  for i in range(len(xvals_test)):\n","    print('Actual:', yvals_test[i], 'Predicted:', np.rint(s.run(predicted_y, feed_dict={input_X: [xvals_test.iloc[i]]})))\n","\n","  y_pred = np.rint(s.run(predicted_y, feed_dict={input_X: xvals_test}))\n","\n","  testacc = accuracy_score(yvals_test, y_pred)\n"," \n","  print(\"\\nTest Accuracy: {0:f}\\n\".format(testacc))\n","\n","  w0=weights_0.eval()\n","  w=[]\n","  #w.append(norm(w0[0:sensor_sizes[0]],2))\n","  for i in range(len(sensor_sizes)):\n","    w.append(norm(w0[cumsum[i]:cumsum[i+1]],2))\n","  print(w)\n","  #Feature selection\n","  if reduction==True:\n","    v=[i for i,x in enumerate(w) if x > 0.1*max(w)]\n","    selected=[]\n","    for i in v:\n","      selected.append(xvals.iloc[:,range(cumsum[i],cumsum[i+1])])\n","    print(selected[0])\n","    xvals_reduced=pd.concat(selected,ignore_index=True, axis=1)\n","    print(xvals_reduced)\n","    acc=0\n","    sensor_sizes_red=[sensor_sizes[i] for i in v]\n","    for i in range(10):\n","      acc=acc+func_modified4(regularizer_rate_0,regularizer_rate_1,num_layers_0, epochs, batch_size, num_classes, sensor_sizes_red,dep_cor,xvals_reduced,yvals,reduction=False)\n","    return(acc/10)\n","  else:\n","    return(testacc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GSmcn81CpgTE"},"outputs":[],"source":["from scipy.stats import pearsonr\n","import numpy as np\n","\n","#function for dependency between m th and n th sensor\n","\n","def dep_cor(rsq_mat,sensor,m,n):\n","  \n","  series = pd.Series(sensor)\n","  cumsum = list(series.cumsum())\n","  cumsum=[0]+cumsum\n","  ind1=list(range(cumsum[m-1],cumsum[m]))\n","  ind2=list(range(cumsum[n-1],cumsum[n]))\n","  cor=rsq_mat.iloc[ind1,ind2]\n","  return(min(cor.apply(max,1)))\n"]},{"cell_type":"code","source":["func_modified3(2,1,10,500,10,3,[2,2],dep_cor,xvals,yvals,False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vQzYN1FhJRRp","executionInfo":{"status":"error","timestamp":1675781646168,"user_tz":-330,"elapsed":7699,"user":{"displayName":"Aytijhya Saha","userId":"15087240692289809888"}},"outputId":"6506c3c9-ab2c-4e5d-a4ad-bc134c9f1e83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["[[-0.19708167  0.1978043   0.06414646 -0.95133424 -0.11305457 -0.42700055\n","   0.29217947 -0.8193025   0.08104351 -0.27448344]\n"," [-0.4879038  -0.18215826 -0.14601058 -0.4990794   0.61015725  0.02099038\n","   0.00872037 -0.17104909  0.42494467 -0.26559058]\n"," [-0.2840223  -0.11200962  0.6110784   0.7704659  -0.0853888   0.4914627\n","   0.39801386 -0.595136   -0.4015481   0.09508768]\n"," [-0.8637055  -0.02585068  0.27894333 -0.5665355   0.29940957 -0.07858607\n","   0.3633453  -0.580989    0.6184      0.30730468]]\n","Epoch:0, Train loss: 0.36 Train acc: 0.317\n","Epoch:1, Train loss: 0.33 Train acc: 0.317\n","Epoch:2, Train loss: 0.31 Train acc: 0.317\n","Epoch:3, Train loss: 0.30 Train acc: 0.317\n","Epoch:4, Train loss: 0.29 Train acc: 0.317\n","Epoch:5, Train loss: 0.28 Train acc: 0.308\n","Epoch:6, Train loss: 0.27 Train acc: 0.300\n","Epoch:7, Train loss: 0.26 Train acc: 0.275\n","Epoch:8, Train loss: 0.24 Train acc: 0.283\n","Epoch:9, Train loss: 0.22 Train acc: 0.400\n","Epoch:10, Train loss: 0.21 Train acc: 0.367\n","Epoch:11, Train loss: 0.20 Train acc: 0.375\n","Epoch:12, Train loss: 0.20 Train acc: 0.517\n","Epoch:13, Train loss: 0.19 Train acc: 0.642\n","Epoch:14, Train loss: 0.19 Train acc: 0.683\n","Epoch:15, Train loss: 0.18 Train acc: 0.683\n","Epoch:16, Train loss: 0.18 Train acc: 0.683\n","Epoch:17, Train loss: 0.17 Train acc: 0.683\n","Epoch:18, Train loss: 0.17 Train acc: 0.683\n","Epoch:19, Train loss: 0.17 Train acc: 0.683\n","Epoch:20, Train loss: 0.16 Train acc: 0.683\n","Epoch:21, Train loss: 0.16 Train acc: 0.683\n","Epoch:22, Train loss: 0.16 Train acc: 0.683\n","Epoch:23, Train loss: 0.15 Train acc: 0.683\n","Epoch:24, Train loss: 0.15 Train acc: 0.683\n","Epoch:25, Train loss: 0.15 Train acc: 0.683\n","Epoch:26, Train loss: 0.15 Train acc: 0.683\n","Epoch:27, Train loss: 0.14 Train acc: 0.683\n","Epoch:28, Train loss: 0.14 Train acc: 0.683\n","Epoch:29, Train loss: 0.14 Train acc: 0.683\n","Epoch:30, Train loss: 0.14 Train acc: 0.683\n","Epoch:31, Train loss: 0.14 Train acc: 0.683\n","Epoch:32, Train loss: 0.13 Train acc: 0.683\n","Epoch:33, Train loss: 0.13 Train acc: 0.683\n","Epoch:34, Train loss: 0.13 Train acc: 0.683\n","Epoch:35, Train loss: 0.13 Train acc: 0.683\n","Epoch:36, Train loss: 0.13 Train acc: 0.683\n","Epoch:37, Train loss: 0.13 Train acc: 0.683\n","Epoch:38, Train loss: 0.12 Train acc: 0.683\n","Epoch:39, Train loss: 0.12 Train acc: 0.683\n","Epoch:40, Train loss: 0.12 Train acc: 0.683\n","Epoch:41, Train loss: 0.12 Train acc: 0.683\n","Epoch:42, Train loss: 0.12 Train acc: 0.683\n","Epoch:43, Train loss: 0.12 Train acc: 0.683\n","Epoch:44, Train loss: 0.12 Train acc: 0.692\n","Epoch:45, Train loss: 0.12 Train acc: 0.692\n","Epoch:46, Train loss: 0.12 Train acc: 0.692\n","Epoch:47, Train loss: 0.12 Train acc: 0.692\n","Epoch:48, Train loss: 0.11 Train acc: 0.692\n","Epoch:49, Train loss: 0.11 Train acc: 0.708\n","Epoch:50, Train loss: 0.11 Train acc: 0.708\n","Epoch:51, Train loss: 0.11 Train acc: 0.708\n","Epoch:52, Train loss: 0.11 Train acc: 0.708\n","Epoch:53, Train loss: 0.11 Train acc: 0.708\n","Epoch:54, Train loss: 0.11 Train acc: 0.708\n","Epoch:55, Train loss: 0.11 Train acc: 0.708\n","Epoch:56, Train loss: 0.11 Train acc: 0.717\n","Epoch:57, Train loss: 0.11 Train acc: 0.733\n","Epoch:58, Train loss: 0.11 Train acc: 0.733\n","Epoch:59, Train loss: 0.11 Train acc: 0.733\n","Epoch:60, Train loss: 0.11 Train acc: 0.733\n","Epoch:61, Train loss: 0.11 Train acc: 0.733\n","Epoch:62, Train loss: 0.10 Train acc: 0.742\n","Epoch:63, Train loss: 0.10 Train acc: 0.750\n","Epoch:64, Train loss: 0.10 Train acc: 0.767\n","Epoch:65, Train loss: 0.10 Train acc: 0.783\n","Epoch:66, Train loss: 0.10 Train acc: 0.800\n","Epoch:67, Train loss: 0.10 Train acc: 0.800\n","Epoch:68, Train loss: 0.10 Train acc: 0.825\n","Epoch:69, Train loss: 0.10 Train acc: 0.825\n","Epoch:70, Train loss: 0.10 Train acc: 0.825\n","Epoch:71, Train loss: 0.10 Train acc: 0.825\n","Epoch:72, Train loss: 0.10 Train acc: 0.825\n","Epoch:73, Train loss: 0.10 Train acc: 0.825\n","Epoch:74, Train loss: 0.10 Train acc: 0.833\n","Epoch:75, Train loss: 0.10 Train acc: 0.842\n","Epoch:76, Train loss: 0.10 Train acc: 0.842\n","Epoch:77, Train loss: 0.10 Train acc: 0.842\n","Epoch:78, Train loss: 0.10 Train acc: 0.842\n","Epoch:79, Train loss: 0.10 Train acc: 0.842\n","Epoch:80, Train loss: 0.10 Train acc: 0.842\n","Epoch:81, Train loss: 0.09 Train acc: 0.850\n","Epoch:82, Train loss: 0.09 Train acc: 0.850\n","Epoch:83, Train loss: 0.09 Train acc: 0.858\n","Epoch:84, Train loss: 0.09 Train acc: 0.867\n","Epoch:85, Train loss: 0.09 Train acc: 0.875\n","Epoch:86, Train loss: 0.09 Train acc: 0.883\n","Epoch:87, Train loss: 0.09 Train acc: 0.892\n","Epoch:88, Train loss: 0.09 Train acc: 0.892\n","Epoch:89, Train loss: 0.09 Train acc: 0.892\n","Epoch:90, Train loss: 0.09 Train acc: 0.892\n","Epoch:91, Train loss: 0.09 Train acc: 0.892\n","Epoch:92, Train loss: 0.09 Train acc: 0.892\n","Epoch:93, Train loss: 0.09 Train acc: 0.892\n","Epoch:94, Train loss: 0.09 Train acc: 0.900\n","Epoch:95, Train loss: 0.09 Train acc: 0.908\n","Epoch:96, Train loss: 0.09 Train acc: 0.908\n","Epoch:97, Train loss: 0.09 Train acc: 0.908\n","Epoch:98, Train loss: 0.09 Train acc: 0.908\n","Epoch:99, Train loss: 0.09 Train acc: 0.908\n","Epoch:100, Train loss: 0.09 Train acc: 0.908\n","Epoch:101, Train loss: 0.09 Train acc: 0.925\n","Epoch:102, Train loss: 0.09 Train acc: 0.925\n","Epoch:103, Train loss: 0.09 Train acc: 0.925\n","Epoch:104, Train loss: 0.09 Train acc: 0.925\n","Epoch:105, Train loss: 0.09 Train acc: 0.925\n","Epoch:106, Train loss: 0.09 Train acc: 0.925\n","Epoch:107, Train loss: 0.09 Train acc: 0.925\n","Epoch:108, Train loss: 0.09 Train acc: 0.925\n","Epoch:109, Train loss: 0.09 Train acc: 0.925\n","Epoch:110, Train loss: 0.08 Train acc: 0.925\n","Epoch:111, Train loss: 0.08 Train acc: 0.925\n","Epoch:112, Train loss: 0.08 Train acc: 0.925\n","Epoch:113, Train loss: 0.08 Train acc: 0.933\n","Epoch:114, Train loss: 0.08 Train acc: 0.942\n","Epoch:115, Train loss: 0.08 Train acc: 0.950\n","Epoch:116, Train loss: 0.08 Train acc: 0.950\n","Epoch:117, Train loss: 0.08 Train acc: 0.950\n","Epoch:118, Train loss: 0.08 Train acc: 0.950\n","Epoch:119, Train loss: 0.08 Train acc: 0.950\n","Epoch:120, Train loss: 0.08 Train acc: 0.950\n","Epoch:121, Train loss: 0.08 Train acc: 0.950\n","Epoch:122, Train loss: 0.08 Train acc: 0.950\n","Epoch:123, Train loss: 0.08 Train acc: 0.950\n","Epoch:124, Train loss: 0.08 Train acc: 0.950\n","Epoch:125, Train loss: 0.08 Train acc: 0.950\n","Epoch:126, Train loss: 0.08 Train acc: 0.950\n","Epoch:127, Train loss: 0.08 Train acc: 0.950\n","Epoch:128, Train loss: 0.08 Train acc: 0.950\n","Epoch:129, Train loss: 0.08 Train acc: 0.950\n","Epoch:130, Train loss: 0.08 Train acc: 0.950\n","Epoch:131, Train loss: 0.08 Train acc: 0.950\n","Epoch:132, Train loss: 0.08 Train acc: 0.950\n","Epoch:133, Train loss: 0.08 Train acc: 0.950\n","Epoch:134, Train loss: 0.08 Train acc: 0.950\n","Epoch:135, Train loss: 0.08 Train acc: 0.950\n","Epoch:136, Train loss: 0.08 Train acc: 0.950\n","Epoch:137, Train loss: 0.08 Train acc: 0.950\n","Epoch:138, Train loss: 0.08 Train acc: 0.950\n","Epoch:139, Train loss: 0.08 Train acc: 0.950\n","Epoch:140, Train loss: 0.08 Train acc: 0.950\n","Epoch:141, Train loss: 0.08 Train acc: 0.950\n","Epoch:142, Train loss: 0.08 Train acc: 0.950\n","Epoch:143, Train loss: 0.08 Train acc: 0.950\n","Epoch:144, Train loss: 0.08 Train acc: 0.950\n","Epoch:145, Train loss: 0.08 Train acc: 0.950\n","Epoch:146, Train loss: 0.08 Train acc: 0.950\n","Epoch:147, Train loss: 0.08 Train acc: 0.950\n","Epoch:148, Train loss: 0.08 Train acc: 0.950\n","Epoch:149, Train loss: 0.08 Train acc: 0.950\n","Epoch:150, Train loss: 0.08 Train acc: 0.950\n","Epoch:151, Train loss: 0.08 Train acc: 0.950\n","Epoch:152, Train loss: 0.08 Train acc: 0.950\n","Epoch:153, Train loss: 0.08 Train acc: 0.950\n","Epoch:154, Train loss: 0.07 Train acc: 0.950\n","Epoch:155, Train loss: 0.07 Train acc: 0.950\n","Epoch:156, Train loss: 0.07 Train acc: 0.950\n","Epoch:157, Train loss: 0.07 Train acc: 0.950\n","Epoch:158, Train loss: 0.07 Train acc: 0.950\n","Epoch:159, Train loss: 0.07 Train acc: 0.950\n","Epoch:160, Train loss: 0.07 Train acc: 0.950\n","Epoch:161, Train loss: 0.07 Train acc: 0.950\n","Epoch:162, Train loss: 0.07 Train acc: 0.950\n","Epoch:163, Train loss: 0.07 Train acc: 0.958\n","Epoch:164, Train loss: 0.07 Train acc: 0.958\n","Epoch:165, Train loss: 0.07 Train acc: 0.958\n","Epoch:166, Train loss: 0.07 Train acc: 0.958\n","Epoch:167, Train loss: 0.07 Train acc: 0.958\n","Epoch:168, Train loss: 0.07 Train acc: 0.958\n","Epoch:169, Train loss: 0.07 Train acc: 0.958\n","Epoch:170, Train loss: 0.07 Train acc: 0.958\n","Epoch:171, Train loss: 0.07 Train acc: 0.967\n","Epoch:172, Train loss: 0.07 Train acc: 0.967\n","Epoch:173, Train loss: 0.07 Train acc: 0.967\n","Epoch:174, Train loss: 0.07 Train acc: 0.967\n","Epoch:175, Train loss: 0.07 Train acc: 0.967\n","Epoch:176, Train loss: 0.07 Train acc: 0.967\n","Epoch:177, Train loss: 0.07 Train acc: 0.967\n","Epoch:178, Train loss: 0.07 Train acc: 0.967\n","Epoch:179, Train loss: 0.07 Train acc: 0.967\n","Epoch:180, Train loss: 0.07 Train acc: 0.967\n","Epoch:181, Train loss: 0.07 Train acc: 0.967\n","Epoch:182, Train loss: 0.07 Train acc: 0.967\n","Epoch:183, Train loss: 0.07 Train acc: 0.967\n","Epoch:184, Train loss: 0.07 Train acc: 0.967\n","Epoch:185, Train loss: 0.07 Train acc: 0.967\n","Epoch:186, Train loss: 0.07 Train acc: 0.967\n","Epoch:187, Train loss: 0.07 Train acc: 0.967\n","Epoch:188, Train loss: 0.07 Train acc: 0.967\n","Epoch:189, Train loss: 0.07 Train acc: 0.967\n","Epoch:190, Train loss: 0.07 Train acc: 0.967\n","Epoch:191, Train loss: 0.07 Train acc: 0.967\n","Epoch:192, Train loss: 0.07 Train acc: 0.967\n","Epoch:193, Train loss: 0.07 Train acc: 0.967\n","Epoch:194, Train loss: 0.07 Train acc: 0.967\n","Epoch:195, Train loss: 0.07 Train acc: 0.967\n","Epoch:196, Train loss: 0.07 Train acc: 0.967\n","Epoch:197, Train loss: 0.07 Train acc: 0.967\n","Epoch:198, Train loss: 0.07 Train acc: 0.967\n","Epoch:199, Train loss: 0.07 Train acc: 0.967\n","Epoch:200, Train loss: 0.07 Train acc: 0.967\n","Epoch:201, Train loss: 0.07 Train acc: 0.967\n","Epoch:202, Train loss: 0.07 Train acc: 0.967\n","Epoch:203, Train loss: 0.07 Train acc: 0.967\n","Epoch:204, Train loss: 0.07 Train acc: 0.967\n","Epoch:205, Train loss: 0.07 Train acc: 0.967\n","Epoch:206, Train loss: 0.07 Train acc: 0.967\n","Epoch:207, Train loss: 0.07 Train acc: 0.967\n","Epoch:208, Train loss: 0.07 Train acc: 0.967\n","Epoch:209, Train loss: 0.07 Train acc: 0.967\n","Epoch:210, Train loss: 0.07 Train acc: 0.967\n","Epoch:211, Train loss: 0.07 Train acc: 0.967\n","Epoch:212, Train loss: 0.07 Train acc: 0.967\n","Epoch:213, Train loss: 0.07 Train acc: 0.967\n","Epoch:214, Train loss: 0.07 Train acc: 0.967\n","Epoch:215, Train loss: 0.07 Train acc: 0.967\n","Epoch:216, Train loss: 0.07 Train acc: 0.967\n","Epoch:217, Train loss: 0.07 Train acc: 0.967\n","Epoch:218, Train loss: 0.07 Train acc: 0.967\n","Epoch:219, Train loss: 0.07 Train acc: 0.967\n","Epoch:220, Train loss: 0.07 Train acc: 0.967\n","Epoch:221, Train loss: 0.07 Train acc: 0.967\n","Epoch:222, Train loss: 0.07 Train acc: 0.967\n","Epoch:223, Train loss: 0.07 Train acc: 0.958\n","Epoch:224, Train loss: 0.07 Train acc: 0.958\n","Epoch:225, Train loss: 0.06 Train acc: 0.958\n","Epoch:226, Train loss: 0.06 Train acc: 0.958\n","Epoch:227, Train loss: 0.06 Train acc: 0.958\n","Epoch:228, Train loss: 0.06 Train acc: 0.958\n","Epoch:229, Train loss: 0.06 Train acc: 0.958\n","Epoch:230, Train loss: 0.06 Train acc: 0.958\n","Epoch:231, Train loss: 0.06 Train acc: 0.958\n","Epoch:232, Train loss: 0.06 Train acc: 0.967\n","Epoch:233, Train loss: 0.06 Train acc: 0.967\n","Epoch:234, Train loss: 0.06 Train acc: 0.967\n","Epoch:235, Train loss: 0.06 Train acc: 0.967\n","Epoch:236, Train loss: 0.06 Train acc: 0.967\n","Epoch:237, Train loss: 0.06 Train acc: 0.967\n","Epoch:238, Train loss: 0.06 Train acc: 0.967\n","Epoch:239, Train loss: 0.06 Train acc: 0.967\n","Epoch:240, Train loss: 0.06 Train acc: 0.967\n","Epoch:241, Train loss: 0.06 Train acc: 0.967\n","Epoch:242, Train loss: 0.06 Train acc: 0.967\n","Epoch:243, Train loss: 0.06 Train acc: 0.967\n","Epoch:244, Train loss: 0.06 Train acc: 0.967\n","Epoch:245, Train loss: 0.06 Train acc: 0.967\n","Epoch:246, Train loss: 0.06 Train acc: 0.967\n","Epoch:247, Train loss: 0.06 Train acc: 0.967\n","Epoch:248, Train loss: 0.06 Train acc: 0.967\n","Epoch:249, Train loss: 0.06 Train acc: 0.967\n","Epoch:250, Train loss: 0.06 Train acc: 0.967\n","Epoch:251, Train loss: 0.06 Train acc: 0.967\n","Epoch:252, Train loss: 0.06 Train acc: 0.967\n","Epoch:253, Train loss: 0.06 Train acc: 0.967\n","Epoch:254, Train loss: 0.06 Train acc: 0.967\n","Epoch:255, Train loss: 0.06 Train acc: 0.967\n","Epoch:256, Train loss: 0.06 Train acc: 0.967\n","Epoch:257, Train loss: 0.06 Train acc: 0.967\n","Epoch:258, Train loss: 0.06 Train acc: 0.967\n","Epoch:259, Train loss: 0.06 Train acc: 0.967\n","Epoch:260, Train loss: 0.06 Train acc: 0.967\n","Epoch:261, Train loss: 0.06 Train acc: 0.967\n","Epoch:262, Train loss: 0.06 Train acc: 0.967\n","Epoch:263, Train loss: 0.06 Train acc: 0.967\n","Epoch:264, Train loss: 0.06 Train acc: 0.967\n","Epoch:265, Train loss: 0.06 Train acc: 0.967\n","Epoch:266, Train loss: 0.06 Train acc: 0.967\n","Epoch:267, Train loss: 0.06 Train acc: 0.967\n","Epoch:268, Train loss: 0.06 Train acc: 0.967\n","Epoch:269, Train loss: 0.06 Train acc: 0.967\n","Epoch:270, Train loss: 0.06 Train acc: 0.967\n","Epoch:271, Train loss: 0.06 Train acc: 0.967\n","Epoch:272, Train loss: 0.06 Train acc: 0.967\n","Epoch:273, Train loss: 0.06 Train acc: 0.967\n","Epoch:274, Train loss: 0.06 Train acc: 0.967\n","Epoch:275, Train loss: 0.06 Train acc: 0.967\n","Epoch:276, Train loss: 0.06 Train acc: 0.958\n","Epoch:277, Train loss: 0.06 Train acc: 0.958\n","Epoch:278, Train loss: 0.06 Train acc: 0.958\n","Epoch:279, Train loss: 0.06 Train acc: 0.958\n","Epoch:280, Train loss: 0.06 Train acc: 0.958\n","Epoch:281, Train loss: 0.06 Train acc: 0.958\n","Epoch:282, Train loss: 0.06 Train acc: 0.967\n","Epoch:283, Train loss: 0.06 Train acc: 0.967\n","Epoch:284, Train loss: 0.06 Train acc: 0.967\n","Epoch:285, Train loss: 0.06 Train acc: 0.967\n","Epoch:286, Train loss: 0.06 Train acc: 0.967\n","Epoch:287, Train loss: 0.06 Train acc: 0.967\n","Epoch:288, Train loss: 0.06 Train acc: 0.967\n","Epoch:289, Train loss: 0.06 Train acc: 0.967\n","Epoch:290, Train loss: 0.06 Train acc: 0.967\n","Epoch:291, Train loss: 0.06 Train acc: 0.967\n","Epoch:292, Train loss: 0.06 Train acc: 0.967\n","Epoch:293, Train loss: 0.06 Train acc: 0.967\n","Epoch:294, Train loss: 0.06 Train acc: 0.967\n","Epoch:295, Train loss: 0.06 Train acc: 0.967\n","Epoch:296, Train loss: 0.06 Train acc: 0.967\n","Epoch:297, Train loss: 0.06 Train acc: 0.967\n","Epoch:298, Train loss: 0.06 Train acc: 0.967\n","Epoch:299, Train loss: 0.06 Train acc: 0.967\n","Epoch:300, Train loss: 0.06 Train acc: 0.967\n","Epoch:301, Train loss: 0.06 Train acc: 0.967\n","Epoch:302, Train loss: 0.06 Train acc: 0.967\n","Epoch:303, Train loss: 0.06 Train acc: 0.967\n","Epoch:304, Train loss: 0.06 Train acc: 0.967\n","Epoch:305, Train loss: 0.06 Train acc: 0.967\n","Epoch:306, Train loss: 0.06 Train acc: 0.967\n","Epoch:307, Train loss: 0.06 Train acc: 0.967\n","Epoch:308, Train loss: 0.06 Train acc: 0.967\n","Epoch:309, Train loss: 0.06 Train acc: 0.967\n","Epoch:310, Train loss: 0.06 Train acc: 0.967\n","Epoch:311, Train loss: 0.06 Train acc: 0.967\n","Epoch:312, Train loss: 0.06 Train acc: 0.967\n","Epoch:313, Train loss: 0.06 Train acc: 0.967\n","Epoch:314, Train loss: 0.06 Train acc: 0.967\n","Epoch:315, Train loss: 0.06 Train acc: 0.967\n","Epoch:316, Train loss: 0.06 Train acc: 0.967\n","Epoch:317, Train loss: 0.06 Train acc: 0.967\n","Epoch:318, Train loss: 0.06 Train acc: 0.967\n","Epoch:319, Train loss: 0.06 Train acc: 0.967\n","Epoch:320, Train loss: 0.06 Train acc: 0.967\n","Epoch:321, Train loss: 0.06 Train acc: 0.967\n","Epoch:322, Train loss: 0.06 Train acc: 0.967\n","Epoch:323, Train loss: 0.06 Train acc: 0.967\n","Epoch:324, Train loss: 0.06 Train acc: 0.967\n","Epoch:325, Train loss: 0.06 Train acc: 0.967\n","Epoch:326, Train loss: 0.06 Train acc: 0.967\n","Epoch:327, Train loss: 0.06 Train acc: 0.967\n","Epoch:328, Train loss: 0.06 Train acc: 0.967\n","Epoch:329, Train loss: 0.06 Train acc: 0.967\n","Epoch:330, Train loss: 0.06 Train acc: 0.967\n","Epoch:331, Train loss: 0.06 Train acc: 0.967\n","Epoch:332, Train loss: 0.06 Train acc: 0.967\n","Epoch:333, Train loss: 0.06 Train acc: 0.967\n","Epoch:334, Train loss: 0.06 Train acc: 0.967\n","Epoch:335, Train loss: 0.06 Train acc: 0.967\n","Epoch:336, Train loss: 0.06 Train acc: 0.967\n","Epoch:337, Train loss: 0.06 Train acc: 0.967\n","Epoch:338, Train loss: 0.06 Train acc: 0.967\n","Epoch:339, Train loss: 0.06 Train acc: 0.967\n","Epoch:340, Train loss: 0.06 Train acc: 0.967\n","Epoch:341, Train loss: 0.06 Train acc: 0.967\n","Epoch:342, Train loss: 0.06 Train acc: 0.967\n","Epoch:343, Train loss: 0.06 Train acc: 0.967\n","Epoch:344, Train loss: 0.06 Train acc: 0.967\n","Epoch:345, Train loss: 0.06 Train acc: 0.967\n","Epoch:346, Train loss: 0.06 Train acc: 0.967\n","Epoch:347, Train loss: 0.06 Train acc: 0.967\n","Epoch:348, Train loss: 0.06 Train acc: 0.967\n","Epoch:349, Train loss: 0.06 Train acc: 0.967\n","Epoch:350, Train loss: 0.06 Train acc: 0.967\n","Epoch:351, Train loss: 0.06 Train acc: 0.967\n","Epoch:352, Train loss: 0.06 Train acc: 0.967\n","Epoch:353, Train loss: 0.06 Train acc: 0.967\n","Epoch:354, Train loss: 0.06 Train acc: 0.967\n","Epoch:355, Train loss: 0.06 Train acc: 0.967\n","Epoch:356, Train loss: 0.06 Train acc: 0.967\n","Epoch:357, Train loss: 0.06 Train acc: 0.967\n","Epoch:358, Train loss: 0.06 Train acc: 0.967\n","Epoch:359, Train loss: 0.06 Train acc: 0.967\n","Epoch:360, Train loss: 0.06 Train acc: 0.967\n","Epoch:361, Train loss: 0.06 Train acc: 0.967\n","Epoch:362, Train loss: 0.06 Train acc: 0.967\n","Epoch:363, Train loss: 0.06 Train acc: 0.967\n","Epoch:364, Train loss: 0.06 Train acc: 0.967\n","Epoch:365, Train loss: 0.06 Train acc: 0.967\n","Epoch:366, Train loss: 0.06 Train acc: 0.967\n","Epoch:367, Train loss: 0.06 Train acc: 0.967\n","Epoch:368, Train loss: 0.06 Train acc: 0.967\n","Epoch:369, Train loss: 0.06 Train acc: 0.967\n","Epoch:370, Train loss: 0.06 Train acc: 0.967\n","Epoch:371, Train loss: 0.06 Train acc: 0.967\n","Epoch:372, Train loss: 0.06 Train acc: 0.967\n","Epoch:373, Train loss: 0.06 Train acc: 0.967\n","Epoch:374, Train loss: 0.06 Train acc: 0.967\n","Epoch:375, Train loss: 0.06 Train acc: 0.967\n","Epoch:376, Train loss: 0.06 Train acc: 0.967\n","Epoch:377, Train loss: 0.06 Train acc: 0.967\n","Epoch:378, Train loss: 0.06 Train acc: 0.967\n","Epoch:379, Train loss: 0.06 Train acc: 0.967\n","Epoch:380, Train loss: 0.06 Train acc: 0.967\n","Epoch:381, Train loss: 0.06 Train acc: 0.967\n","Epoch:382, Train loss: 0.06 Train acc: 0.967\n","Epoch:383, Train loss: 0.06 Train acc: 0.967\n","Epoch:384, Train loss: 0.06 Train acc: 0.967\n","Epoch:385, Train loss: 0.06 Train acc: 0.967\n","Epoch:386, Train loss: 0.06 Train acc: 0.967\n","Epoch:387, Train loss: 0.06 Train acc: 0.967\n","Epoch:388, Train loss: 0.06 Train acc: 0.967\n","Epoch:389, Train loss: 0.06 Train acc: 0.967\n","Epoch:390, Train loss: 0.06 Train acc: 0.967\n","Epoch:391, Train loss: 0.06 Train acc: 0.967\n","Epoch:392, Train loss: 0.06 Train acc: 0.967\n","Epoch:393, Train loss: 0.06 Train acc: 0.967\n","Epoch:394, Train loss: 0.06 Train acc: 0.967\n","Epoch:395, Train loss: 0.06 Train acc: 0.967\n","Epoch:396, Train loss: 0.06 Train acc: 0.967\n","Epoch:397, Train loss: 0.06 Train acc: 0.967\n","Epoch:398, Train loss: 0.06 Train acc: 0.967\n","Epoch:399, Train loss: 0.06 Train acc: 0.967\n","Epoch:400, Train loss: 0.06 Train acc: 0.967\n","Epoch:401, Train loss: 0.06 Train acc: 0.967\n","Epoch:402, Train loss: 0.06 Train acc: 0.967\n","Epoch:403, Train loss: 0.06 Train acc: 0.967\n","Epoch:404, Train loss: 0.06 Train acc: 0.967\n","Epoch:405, Train loss: 0.06 Train acc: 0.967\n","Epoch:406, Train loss: 0.06 Train acc: 0.967\n","Epoch:407, Train loss: 0.06 Train acc: 0.967\n","Epoch:408, Train loss: 0.06 Train acc: 0.967\n","Epoch:409, Train loss: 0.06 Train acc: 0.967\n","Epoch:410, Train loss: 0.06 Train acc: 0.967\n","Epoch:411, Train loss: 0.06 Train acc: 0.967\n","Epoch:412, Train loss: 0.06 Train acc: 0.967\n","Epoch:413, Train loss: 0.06 Train acc: 0.967\n","Epoch:414, Train loss: 0.06 Train acc: 0.967\n","Epoch:415, Train loss: 0.06 Train acc: 0.967\n","Epoch:416, Train loss: 0.06 Train acc: 0.967\n","Epoch:417, Train loss: 0.06 Train acc: 0.967\n","Epoch:418, Train loss: 0.06 Train acc: 0.967\n","Epoch:419, Train loss: 0.06 Train acc: 0.967\n","Epoch:420, Train loss: 0.06 Train acc: 0.967\n","Epoch:421, Train loss: 0.06 Train acc: 0.967\n","Epoch:422, Train loss: 0.06 Train acc: 0.967\n","Epoch:423, Train loss: 0.06 Train acc: 0.967\n","Epoch:424, Train loss: 0.06 Train acc: 0.967\n","Epoch:425, Train loss: 0.06 Train acc: 0.967\n","Epoch:426, Train loss: 0.06 Train acc: 0.967\n","Epoch:427, Train loss: 0.06 Train acc: 0.967\n","Epoch:428, Train loss: 0.06 Train acc: 0.967\n","Epoch:429, Train loss: 0.06 Train acc: 0.967\n","Epoch:430, Train loss: 0.06 Train acc: 0.967\n","Epoch:431, Train loss: 0.06 Train acc: 0.967\n","Epoch:432, Train loss: 0.06 Train acc: 0.967\n","Epoch:433, Train loss: 0.06 Train acc: 0.967\n","Epoch:434, Train loss: 0.06 Train acc: 0.967\n","Epoch:435, Train loss: 0.06 Train acc: 0.967\n","Epoch:436, Train loss: 0.06 Train acc: 0.967\n","Epoch:437, Train loss: 0.06 Train acc: 0.967\n","Epoch:438, Train loss: 0.06 Train acc: 0.967\n","Epoch:439, Train loss: 0.06 Train acc: 0.967\n","Epoch:440, Train loss: 0.06 Train acc: 0.967\n","Epoch:441, Train loss: 0.06 Train acc: 0.967\n","Epoch:442, Train loss: 0.06 Train acc: 0.967\n","Epoch:443, Train loss: 0.06 Train acc: 0.967\n","Epoch:444, Train loss: 0.06 Train acc: 0.967\n","Epoch:445, Train loss: 0.06 Train acc: 0.967\n","Epoch:446, Train loss: 0.06 Train acc: 0.967\n","Epoch:447, Train loss: 0.06 Train acc: 0.967\n","Epoch:448, Train loss: 0.06 Train acc: 0.967\n","Epoch:449, Train loss: 0.06 Train acc: 0.967\n","Epoch:450, Train loss: 0.06 Train acc: 0.967\n","Epoch:451, Train loss: 0.06 Train acc: 0.967\n","Epoch:452, Train loss: 0.06 Train acc: 0.967\n","Epoch:453, Train loss: 0.06 Train acc: 0.967\n","Epoch:454, Train loss: 0.06 Train acc: 0.967\n","Epoch:455, Train loss: 0.06 Train acc: 0.967\n","Epoch:456, Train loss: 0.06 Train acc: 0.967\n","Epoch:457, Train loss: 0.06 Train acc: 0.967\n","Epoch:458, Train loss: 0.06 Train acc: 0.967\n","Epoch:459, Train loss: 0.06 Train acc: 0.967\n","Epoch:460, Train loss: 0.06 Train acc: 0.967\n","Epoch:461, Train loss: 0.06 Train acc: 0.967\n","Epoch:462, Train loss: 0.06 Train acc: 0.967\n","Epoch:463, Train loss: 0.06 Train acc: 0.967\n","Epoch:464, Train loss: 0.06 Train acc: 0.967\n","Epoch:465, Train loss: 0.06 Train acc: 0.967\n","Epoch:466, Train loss: 0.06 Train acc: 0.967\n","Epoch:467, Train loss: 0.06 Train acc: 0.967\n","Epoch:468, Train loss: 0.06 Train acc: 0.967\n","Epoch:469, Train loss: 0.06 Train acc: 0.967\n","Epoch:470, Train loss: 0.06 Train acc: 0.967\n","Epoch:471, Train loss: 0.06 Train acc: 0.967\n","Epoch:472, Train loss: 0.06 Train acc: 0.967\n","Epoch:473, Train loss: 0.06 Train acc: 0.967\n","Epoch:474, Train loss: 0.06 Train acc: 0.967\n","Epoch:475, Train loss: 0.06 Train acc: 0.967\n","Epoch:476, Train loss: 0.06 Train acc: 0.967\n","Epoch:477, Train loss: 0.06 Train acc: 0.967\n","Epoch:478, Train loss: 0.06 Train acc: 0.967\n","Epoch:479, Train loss: 0.06 Train acc: 0.967\n","Epoch:480, Train loss: 0.06 Train acc: 0.967\n","Epoch:481, Train loss: 0.06 Train acc: 0.967\n","Epoch:482, Train loss: 0.06 Train acc: 0.967\n","Epoch:483, Train loss: 0.06 Train acc: 0.967\n","Epoch:484, Train loss: 0.06 Train acc: 0.967\n","Epoch:485, Train loss: 0.06 Train acc: 0.967\n","Epoch:486, Train loss: 0.06 Train acc: 0.967\n","Epoch:487, Train loss: 0.06 Train acc: 0.967\n","Epoch:488, Train loss: 0.06 Train acc: 0.967\n","Epoch:489, Train loss: 0.06 Train acc: 0.967\n","Epoch:490, Train loss: 0.06 Train acc: 0.967\n","Epoch:491, Train loss: 0.06 Train acc: 0.967\n","Epoch:492, Train loss: 0.06 Train acc: 0.967\n","Epoch:493, Train loss: 0.06 Train acc: 0.967\n","Epoch:494, Train loss: 0.06 Train acc: 0.967\n","Epoch:495, Train loss: 0.06 Train acc: 0.967\n","Epoch:496, Train loss: 0.06 Train acc: 0.967\n","Epoch:497, Train loss: 0.06 Train acc: 0.967\n","Epoch:498, Train loss: 0.06 Train acc: 0.967\n","Epoch:499, Train loss: 0.06 Train acc: 0.967\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 1. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 1. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 0. 1.] Predicted: [[0. 0. 1.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [1. 0. 0.] Predicted: [[1. 0. 0.]]\n","Actual: [0. 1. 0.] Predicted: [[0. 0. 0.]]\n","30\n","30\n","\n","Test Accuracy: 0.633333\n","\n","[3.0789301, 3.4587302]\n"]},{"output_type":"error","ename":"FailedPreconditionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1361\u001b[0m                                       target_list, run_metadata)\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1453\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1454\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_76\n\t [[{{node _retval_Variable_76_0_0}}]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-bdfdf826387e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfunc_modified3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdep_cor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxvals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myvals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-27-f7e43fccdb46>\u001b[0m in \u001b[0;36mfunc_modified3\u001b[0;34m(regularizer_rate_0, regularizer_rate_1, num_layers_0, epochs, batch_size, num_classes, sensor_sizes, dep, xvals, yvals, reduction)\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mbias_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0mbias_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m   \u001b[0mw0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   2005\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m     \"\"\"\n\u001b[0;32m-> 2007\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    993\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \"\"\"\n\u001b[0;32m--> 995\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Use ref() instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5745\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5746\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5747\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1371\u001b[0m                            run_metadata)\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1394\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1396\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nAttempting to use uninitialized value Variable_76\n\t [[{{node _retval_Variable_76_0_0}}]]"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0IcT6bcPlkW"},"outputs":[],"source":["f1=iris['SepalLengthCm']\n","f2=iris['SepalWidthCm']\n","f3=iris['PetalLengthCm']\n","f4=iris['PetalWidthCm']\n","e1=f1+np.random.normal(loc=0.0, scale=0.05, size=150)\n","e2=f3+np.random.normal(loc=0.0, scale=0.05, size=150)\n","e3=f4+np.random.normal(loc=0.0, scale=0.05, size=150)\n","xvals=pd.concat([f1,f2,e1,f3,f4,e2,e3], axis=1, ignore_index=True).astype(np.float32)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hOVtX1kvt1cG","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"7d49ba0d-9a22-4132-c5e7-2088f54c3b98","executionInfo":{"status":"ok","timestamp":1675575089690,"user_tz":-330,"elapsed":695661,"user":{"displayName":"Aytijhya Saha","userId":"15087240692289809888"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 1/10] END .............hidden_layer_sizes=1;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 2/10] END .............hidden_layer_sizes=1;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 3/10] END .............hidden_layer_sizes=1;, score=0.000 total time=   0.5s\n","[CV 4/10] END .............hidden_layer_sizes=1;, score=0.000 total time=   0.1s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 5/10] END .............hidden_layer_sizes=1;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 6/10] END .............hidden_layer_sizes=1;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 7/10] END .............hidden_layer_sizes=1;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 8/10] END .............hidden_layer_sizes=1;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 9/10] END .............hidden_layer_sizes=1;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 10/10] END ............hidden_layer_sizes=1;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 1/10] END .............hidden_layer_sizes=3;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 2/10] END .............hidden_layer_sizes=3;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 3/10] END .............hidden_layer_sizes=3;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 4/10] END .............hidden_layer_sizes=3;, score=0.933 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 5/10] END .............hidden_layer_sizes=3;, score=0.733 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 6/10] END .............hidden_layer_sizes=3;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 7/10] END .............hidden_layer_sizes=3;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 8/10] END .............hidden_layer_sizes=3;, score=0.000 total time=   0.5s\n","[CV 9/10] END .............hidden_layer_sizes=3;, score=0.000 total time=   0.4s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 10/10] END ............hidden_layer_sizes=3;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 1/10] END .............hidden_layer_sizes=5;, score=1.000 total time=   0.6s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 2/10] END .............hidden_layer_sizes=5;, score=1.000 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 3/10] END .............hidden_layer_sizes=5;, score=0.933 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 4/10] END .............hidden_layer_sizes=5;, score=0.333 total time=   0.7s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 5/10] END .............hidden_layer_sizes=5;, score=0.000 total time=   0.7s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 6/10] END .............hidden_layer_sizes=5;, score=0.000 total time=   0.7s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 7/10] END .............hidden_layer_sizes=5;, score=0.267 total time=   0.7s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 8/10] END .............hidden_layer_sizes=5;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 9/10] END .............hidden_layer_sizes=5;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 10/10] END ............hidden_layer_sizes=5;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 1/10] END .............hidden_layer_sizes=7;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 2/10] END .............hidden_layer_sizes=7;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 3/10] END .............hidden_layer_sizes=7;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 4/10] END .............hidden_layer_sizes=7;, score=0.933 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 5/10] END .............hidden_layer_sizes=7;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 6/10] END .............hidden_layer_sizes=7;, score=0.867 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 7/10] END .............hidden_layer_sizes=7;, score=0.333 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 8/10] END .............hidden_layer_sizes=7;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 9/10] END .............hidden_layer_sizes=7;, score=0.533 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 10/10] END ............hidden_layer_sizes=7;, score=0.800 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 1/10] END .............hidden_layer_sizes=9;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 2/10] END .............hidden_layer_sizes=9;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 3/10] END .............hidden_layer_sizes=9;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 4/10] END .............hidden_layer_sizes=9;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 5/10] END .............hidden_layer_sizes=9;, score=0.600 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 6/10] END .............hidden_layer_sizes=9;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 7/10] END .............hidden_layer_sizes=9;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 8/10] END .............hidden_layer_sizes=9;, score=0.133 total time=   0.7s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 9/10] END .............hidden_layer_sizes=9;, score=0.800 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 10/10] END ............hidden_layer_sizes=9;, score=1.000 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 1/10] END ............hidden_layer_sizes=11;, score=1.000 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 2/10] END ............hidden_layer_sizes=11;, score=1.000 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 3/10] END ............hidden_layer_sizes=11;, score=1.000 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 4/10] END ............hidden_layer_sizes=11;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 5/10] END ............hidden_layer_sizes=11;, score=0.733 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 6/10] END ............hidden_layer_sizes=11;, score=0.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 7/10] END ............hidden_layer_sizes=11;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 8/10] END ............hidden_layer_sizes=11;, score=0.267 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 9/10] END ............hidden_layer_sizes=11;, score=0.400 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 10/10] END ...........hidden_layer_sizes=11;, score=0.667 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 1/10] END ............hidden_layer_sizes=13;, score=1.000 total time=   0.6s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 2/10] END ............hidden_layer_sizes=13;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 3/10] END ............hidden_layer_sizes=13;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 4/10] END ............hidden_layer_sizes=13;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 5/10] END ............hidden_layer_sizes=13;, score=0.800 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 6/10] END ............hidden_layer_sizes=13;, score=0.800 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 7/10] END ............hidden_layer_sizes=13;, score=0.533 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 8/10] END ............hidden_layer_sizes=13;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 9/10] END ............hidden_layer_sizes=13;, score=0.467 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 10/10] END ...........hidden_layer_sizes=13;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 1/10] END ............hidden_layer_sizes=15;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 2/10] END ............hidden_layer_sizes=15;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 3/10] END ............hidden_layer_sizes=15;, score=1.000 total time=   0.6s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 4/10] END ............hidden_layer_sizes=15;, score=0.333 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 5/10] END ............hidden_layer_sizes=15;, score=0.800 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 6/10] END ............hidden_layer_sizes=15;, score=0.667 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 7/10] END ............hidden_layer_sizes=15;, score=1.000 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 8/10] END ............hidden_layer_sizes=15;, score=1.000 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 9/10] END ............hidden_layer_sizes=15;, score=0.800 total time=   0.7s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 10/10] END ...........hidden_layer_sizes=15;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 1/10] END ............hidden_layer_sizes=17;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 2/10] END ............hidden_layer_sizes=17;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 3/10] END ............hidden_layer_sizes=17;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 4/10] END ............hidden_layer_sizes=17;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 5/10] END ............hidden_layer_sizes=17;, score=0.800 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 6/10] END ............hidden_layer_sizes=17;, score=0.867 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 7/10] END ............hidden_layer_sizes=17;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 8/10] END ............hidden_layer_sizes=17;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 9/10] END ............hidden_layer_sizes=17;, score=0.800 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 10/10] END ...........hidden_layer_sizes=17;, score=0.667 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 1/10] END ............hidden_layer_sizes=19;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 2/10] END ............hidden_layer_sizes=19;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 3/10] END ............hidden_layer_sizes=19;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 4/10] END ............hidden_layer_sizes=19;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 5/10] END ............hidden_layer_sizes=19;, score=0.733 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 6/10] END ............hidden_layer_sizes=19;, score=0.867 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 7/10] END ............hidden_layer_sizes=19;, score=1.000 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 8/10] END ............hidden_layer_sizes=19;, score=0.933 total time=   0.5s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 9/10] END ............hidden_layer_sizes=19;, score=0.267 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV 10/10] END ...........hidden_layer_sizes=19;, score=1.000 total time=   0.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Best number of nodes in hidden layer:  {'hidden_layer_sizes': 17}\n","\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.900000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.900000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.900000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.566667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.866667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.866667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.900000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.866667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 1.000000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.933333\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.966667\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["   Lambda  Mu  Test Accuracy  Number of sensors selected Selected sensors\n","0       0   0       0.953333                           3        [0, 1, 2]\n","1       0   2       0.940000                           1              [1]\n","2       0   5       0.930000                           1              [1]\n","3       2   0       0.953333                           2           [0, 1]\n","4       2   2       0.956667                           1              [1]\n","5       2   5       0.966667                           1              [1]\n","6       5   0       0.973333                           1              [1]\n","7       5   2       0.970000                           1              [1]\n","8       5   5       0.970000                           1              [1]"],"text/html":["\n","  <div id=\"df-c851642c-74aa-479d-bbac-8d15f262bab6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Lambda</th>\n","      <th>Mu</th>\n","      <th>Test Accuracy</th>\n","      <th>Number of sensors selected</th>\n","      <th>Selected sensors</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.953333</td>\n","      <td>3</td>\n","      <td>[0, 1, 2]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0.940000</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0.930000</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0.953333</td>\n","      <td>2</td>\n","      <td>[0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0.956667</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>0.966667</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0.973333</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>0.970000</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>0.970000</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c851642c-74aa-479d-bbac-8d15f262bab6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c851642c-74aa-479d-bbac-8d15f262bab6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c851642c-74aa-479d-bbac-8d15f262bab6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","# Define the parameter grid for the number of nodes in the hidden layer\n","param_grid = {'hidden_layer_sizes': np.arange(1, 20, 2)}\n","\n","# Create a MLPClassifier object\n","mlp = MLPClassifier(max_iter=1000)\n","\n","# Create a GridSearchCV object\n","grid_search = GridSearchCV(mlp, param_grid, cv=10, scoring='accuracy',verbose = 3)\n","\n","# Fit the GridSearchCV object to the data\n","grid_search.fit(xvals, yvals)\n","\n","# Print the best number of nodes in the hidden layer\n","print(\"Best number of nodes in hidden layer: \", grid_search.best_params_)\n","from itertools import repeat\n","result=[]\n","for i in [0,2,5]:\n","  for j in [0,2,5]:\n","    x=func_modified3(i,j,grid_search.best_params_['hidden_layer_sizes'],400,10,3,[2,3,2],dep_cor,xvals,yvals,True)\n","    result.append([i,j,x[0],x[1],x[2]])\n","\n","result=pd.DataFrame(result)\n","result.columns =[\"Lambda\",\"Mu\", \"Test Accuracy\", \"Number of sensors selected\",\"Selected sensors\"]\n","result"]},{"cell_type":"code","source":["result_iris2=result"],"metadata":{"id":"IhDW0OzWWFhc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1470,"status":"ok","timestamp":1675584652651,"user":{"displayName":"Aytijhya Saha","userId":"15087240692289809888"},"user_tz":-330},"id":"dtAx6qhBiOUg","colab":{"base_uri":"https://localhost:8080/","height":523},"outputId":"662f0517-6d9c-4e1e-c120-cbebddefdbad"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129) have mixed types.Specify dtype option on import or set low_memory=False.\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]},{"output_type":"execute_result","data":{"text/plain":["            2         3         4         5         6         7         8    \\\n","1     -0.498823 -0.353696 -0.599967 -0.640209 -0.508537  0.504313  0.519048   \n","2     -0.344104 -0.304448 -0.427355 -0.491356 -0.504699  0.348537  0.402966   \n","3     -0.119290 -0.236096 -0.269089 -0.330763 -0.400975  0.117085  0.231118   \n","4     -0.108947 -0.236318 -0.046722 -0.099488  0.341659  0.102857  0.221204   \n","5      0.110479 -0.181176 -0.084136 -0.121640 -0.242369 -0.151210  0.038570   \n","...         ...       ...       ...       ...       ...       ...       ...   \n","13906 -0.307916 -0.246847 -0.485160 -0.549709 -0.458386  0.414751  0.421862   \n","13907 -0.143795 -0.249012 -0.151498 -0.207163 -0.155137  0.077420  0.166321   \n","13908  1.901950  0.664126  1.848079  1.812697  1.423620 -1.601135 -1.559541   \n","13909 -0.306050 -0.301808 -0.353361 -0.399921 -0.338603  0.244922  0.297209   \n","13910  2.581928  0.929003  2.725796  2.775733  2.373641 -2.141793 -2.569632   \n","\n","            9         10        11   ...       120       121       122  \\\n","1      0.420417 -0.656019 -0.313086  ...  0.925279  0.607139 -1.165980   \n","2      0.400031 -0.522842 -0.287665  ...  0.875453  0.646466 -1.086196   \n","3      0.364061 -0.308821 -0.244310  ...  0.782796  0.613568 -0.964482   \n","4      0.366421 -0.296068 -0.243619  ...  0.758672  0.606373 -0.948180   \n","5      0.332179 -0.083764 -0.203216  ...  0.651558  0.563989 -0.807353   \n","...         ...       ...       ...  ...       ...       ...       ...   \n","13906  0.335800 -0.236345 -0.209829  ...  0.879392  0.552717 -0.994872   \n","13907  0.214673 -0.265725 -0.260120  ...  0.130994  0.120197 -0.279282   \n","13908 -2.055822  2.693727  0.505053  ... -2.643781 -1.644654  2.188036   \n","13909  0.287035 -0.451244 -0.293780  ...  0.471342  0.329141 -0.672849   \n","13910 -4.357904  3.590064  0.681464  ... -6.074370 -5.776044  4.655599   \n","\n","            123       124       125       126       127       128       129  \n","1     -0.452359 -1.259691 -1.141841 -1.226102  1.038312  0.951309  0.641065  \n","2     -0.385757 -1.173395 -1.069507 -1.190985  0.956254  0.896151  0.684262  \n","3     -0.145462 -1.092653 -1.001250 -1.115337  0.850126  0.808405  0.655673  \n","4     -0.123006 -0.982531 -0.913377 -1.045200  0.826851  0.788437  0.648965  \n","5      0.237454 -0.980268 -0.892513 -1.020654  0.708167  0.685640  0.572631  \n","...         ...       ...       ...       ...       ...       ...       ...  \n","13906 -0.693892 -1.160764 -1.036392 -0.955375  0.967338  0.885127  0.555494  \n","13907 -0.184373 -0.375570 -0.477159 -0.521098  0.096686  0.067103  0.158543  \n","13908  2.528193  1.933941  0.953627  0.991928 -2.603609 -2.664302 -1.920199  \n","13909 -0.545487 -0.737872 -0.697882 -0.699366  0.489014  0.449561  0.310945  \n","13910  5.028201  4.323686  2.757732  2.884996 -5.655662 -6.034363 -5.224756  \n","\n","[13910 rows x 128 columns]"],"text/html":["\n","  <div id=\"df-65b4ed0b-3222-4a59-b6c6-368d52ae05bf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>...</th>\n","      <th>120</th>\n","      <th>121</th>\n","      <th>122</th>\n","      <th>123</th>\n","      <th>124</th>\n","      <th>125</th>\n","      <th>126</th>\n","      <th>127</th>\n","      <th>128</th>\n","      <th>129</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.498823</td>\n","      <td>-0.353696</td>\n","      <td>-0.599967</td>\n","      <td>-0.640209</td>\n","      <td>-0.508537</td>\n","      <td>0.504313</td>\n","      <td>0.519048</td>\n","      <td>0.420417</td>\n","      <td>-0.656019</td>\n","      <td>-0.313086</td>\n","      <td>...</td>\n","      <td>0.925279</td>\n","      <td>0.607139</td>\n","      <td>-1.165980</td>\n","      <td>-0.452359</td>\n","      <td>-1.259691</td>\n","      <td>-1.141841</td>\n","      <td>-1.226102</td>\n","      <td>1.038312</td>\n","      <td>0.951309</td>\n","      <td>0.641065</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.344104</td>\n","      <td>-0.304448</td>\n","      <td>-0.427355</td>\n","      <td>-0.491356</td>\n","      <td>-0.504699</td>\n","      <td>0.348537</td>\n","      <td>0.402966</td>\n","      <td>0.400031</td>\n","      <td>-0.522842</td>\n","      <td>-0.287665</td>\n","      <td>...</td>\n","      <td>0.875453</td>\n","      <td>0.646466</td>\n","      <td>-1.086196</td>\n","      <td>-0.385757</td>\n","      <td>-1.173395</td>\n","      <td>-1.069507</td>\n","      <td>-1.190985</td>\n","      <td>0.956254</td>\n","      <td>0.896151</td>\n","      <td>0.684262</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.119290</td>\n","      <td>-0.236096</td>\n","      <td>-0.269089</td>\n","      <td>-0.330763</td>\n","      <td>-0.400975</td>\n","      <td>0.117085</td>\n","      <td>0.231118</td>\n","      <td>0.364061</td>\n","      <td>-0.308821</td>\n","      <td>-0.244310</td>\n","      <td>...</td>\n","      <td>0.782796</td>\n","      <td>0.613568</td>\n","      <td>-0.964482</td>\n","      <td>-0.145462</td>\n","      <td>-1.092653</td>\n","      <td>-1.001250</td>\n","      <td>-1.115337</td>\n","      <td>0.850126</td>\n","      <td>0.808405</td>\n","      <td>0.655673</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.108947</td>\n","      <td>-0.236318</td>\n","      <td>-0.046722</td>\n","      <td>-0.099488</td>\n","      <td>0.341659</td>\n","      <td>0.102857</td>\n","      <td>0.221204</td>\n","      <td>0.366421</td>\n","      <td>-0.296068</td>\n","      <td>-0.243619</td>\n","      <td>...</td>\n","      <td>0.758672</td>\n","      <td>0.606373</td>\n","      <td>-0.948180</td>\n","      <td>-0.123006</td>\n","      <td>-0.982531</td>\n","      <td>-0.913377</td>\n","      <td>-1.045200</td>\n","      <td>0.826851</td>\n","      <td>0.788437</td>\n","      <td>0.648965</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.110479</td>\n","      <td>-0.181176</td>\n","      <td>-0.084136</td>\n","      <td>-0.121640</td>\n","      <td>-0.242369</td>\n","      <td>-0.151210</td>\n","      <td>0.038570</td>\n","      <td>0.332179</td>\n","      <td>-0.083764</td>\n","      <td>-0.203216</td>\n","      <td>...</td>\n","      <td>0.651558</td>\n","      <td>0.563989</td>\n","      <td>-0.807353</td>\n","      <td>0.237454</td>\n","      <td>-0.980268</td>\n","      <td>-0.892513</td>\n","      <td>-1.020654</td>\n","      <td>0.708167</td>\n","      <td>0.685640</td>\n","      <td>0.572631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13906</th>\n","      <td>-0.307916</td>\n","      <td>-0.246847</td>\n","      <td>-0.485160</td>\n","      <td>-0.549709</td>\n","      <td>-0.458386</td>\n","      <td>0.414751</td>\n","      <td>0.421862</td>\n","      <td>0.335800</td>\n","      <td>-0.236345</td>\n","      <td>-0.209829</td>\n","      <td>...</td>\n","      <td>0.879392</td>\n","      <td>0.552717</td>\n","      <td>-0.994872</td>\n","      <td>-0.693892</td>\n","      <td>-1.160764</td>\n","      <td>-1.036392</td>\n","      <td>-0.955375</td>\n","      <td>0.967338</td>\n","      <td>0.885127</td>\n","      <td>0.555494</td>\n","    </tr>\n","    <tr>\n","      <th>13907</th>\n","      <td>-0.143795</td>\n","      <td>-0.249012</td>\n","      <td>-0.151498</td>\n","      <td>-0.207163</td>\n","      <td>-0.155137</td>\n","      <td>0.077420</td>\n","      <td>0.166321</td>\n","      <td>0.214673</td>\n","      <td>-0.265725</td>\n","      <td>-0.260120</td>\n","      <td>...</td>\n","      <td>0.130994</td>\n","      <td>0.120197</td>\n","      <td>-0.279282</td>\n","      <td>-0.184373</td>\n","      <td>-0.375570</td>\n","      <td>-0.477159</td>\n","      <td>-0.521098</td>\n","      <td>0.096686</td>\n","      <td>0.067103</td>\n","      <td>0.158543</td>\n","    </tr>\n","    <tr>\n","      <th>13908</th>\n","      <td>1.901950</td>\n","      <td>0.664126</td>\n","      <td>1.848079</td>\n","      <td>1.812697</td>\n","      <td>1.423620</td>\n","      <td>-1.601135</td>\n","      <td>-1.559541</td>\n","      <td>-2.055822</td>\n","      <td>2.693727</td>\n","      <td>0.505053</td>\n","      <td>...</td>\n","      <td>-2.643781</td>\n","      <td>-1.644654</td>\n","      <td>2.188036</td>\n","      <td>2.528193</td>\n","      <td>1.933941</td>\n","      <td>0.953627</td>\n","      <td>0.991928</td>\n","      <td>-2.603609</td>\n","      <td>-2.664302</td>\n","      <td>-1.920199</td>\n","    </tr>\n","    <tr>\n","      <th>13909</th>\n","      <td>-0.306050</td>\n","      <td>-0.301808</td>\n","      <td>-0.353361</td>\n","      <td>-0.399921</td>\n","      <td>-0.338603</td>\n","      <td>0.244922</td>\n","      <td>0.297209</td>\n","      <td>0.287035</td>\n","      <td>-0.451244</td>\n","      <td>-0.293780</td>\n","      <td>...</td>\n","      <td>0.471342</td>\n","      <td>0.329141</td>\n","      <td>-0.672849</td>\n","      <td>-0.545487</td>\n","      <td>-0.737872</td>\n","      <td>-0.697882</td>\n","      <td>-0.699366</td>\n","      <td>0.489014</td>\n","      <td>0.449561</td>\n","      <td>0.310945</td>\n","    </tr>\n","    <tr>\n","      <th>13910</th>\n","      <td>2.581928</td>\n","      <td>0.929003</td>\n","      <td>2.725796</td>\n","      <td>2.775733</td>\n","      <td>2.373641</td>\n","      <td>-2.141793</td>\n","      <td>-2.569632</td>\n","      <td>-4.357904</td>\n","      <td>3.590064</td>\n","      <td>0.681464</td>\n","      <td>...</td>\n","      <td>-6.074370</td>\n","      <td>-5.776044</td>\n","      <td>4.655599</td>\n","      <td>5.028201</td>\n","      <td>4.323686</td>\n","      <td>2.757732</td>\n","      <td>2.884996</td>\n","      <td>-5.655662</td>\n","      <td>-6.034363</td>\n","      <td>-5.224756</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13910 rows × 128 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65b4ed0b-3222-4a59-b6c6-368d52ae05bf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-65b4ed0b-3222-4a59-b6c6-368d52ae05bf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-65b4ed0b-3222-4a59-b6c6-368d52ae05bf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["data=pd.read_csv('/content/drive/MyDrive/datasets/GasSensor(cleaned in R).csv',header=None)\n","data.drop(0,axis=1,inplace=True)\n","data.drop(0,axis=0,inplace=True)\n","data.dropna() \n","data[1]=data[1].replace(['1'],1)\n","data[1]=data[1].replace(['2'],2)\n","data[1]=data[1].replace(['3'],3)\n","data[1]=data[1].replace(['4'],4)\n","data[1]=data[1].replace(['5'],5)\n","data[1]=data[1].replace(['6'],6)\n","\n","yvals=data[1]\n","yvals=to_categorical(np.asarray(yvals.factorize()[0]))\n","\n","xvals=data.iloc[:,1:129].astype(np.float32)\n","from scipy.stats import zscore\n","for i in range(128):\n","  xvals[i+2]=zscore(xvals[i+2])\n","xvals\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F8QvsrXniwAS","outputId":"7c76d702-8930-4c67-e86f-0d2a8a54efcf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 10 folds for each of 10 candidates, totalling 100 fits\n","[CV 1/10] END .............hidden_layer_sizes=1;, score=0.219 total time=  28.1s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"output_type":"stream","name":"stdout","text":["[CV 2/10] END .............hidden_layer_sizes=1;, score=0.598 total time=   9.8s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"output_type":"stream","name":"stdout","text":["[CV 3/10] END .............hidden_layer_sizes=1;, score=0.254 total time=   3.0s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"output_type":"stream","name":"stdout","text":["[CV 4/10] END .............hidden_layer_sizes=1;, score=0.000 total time=   1.0s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"output_type":"stream","name":"stdout","text":["[CV 5/10] END .............hidden_layer_sizes=1;, score=0.345 total time=   1.6s\n"]}],"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import GridSearchCV\n","from itertools import repeat\n","# Define the parameter grid for the number of nodes in the hidden layer\n","param_grid = {'hidden_layer_sizes': np.arange(1, 20, 2)}\n","\n","# Create a MLPClassifier object\n","mlp = MLPClassifier(max_iter=1000)\n","\n","# Create a GridSearchCV object\n","grid_search = GridSearchCV(mlp, param_grid, cv=10, scoring='accuracy',verbose = 3)\n","\n","# Fit the GridSearchCV object to the data\n","grid_search.fit(xvals, yvals)\n","\n","# Print the best number of nodes in the hidden layer\n","print(\"Best number of nodes in hidden layer: \", grid_search.best_params_)\n","\n"]},{"cell_type":"code","source":["from itertools import repeat\n","result=[]\n","for i in [0,2,5]:\n","  for j in [0,2,5]:\n","    x=func_modified3(i,j,19,400,100,6,list(repeat(8,16)),dep_cor,xvals,yvals,True)\n","    result.append([i,j,x[0],x[1],x[2]])\n","\n","result_gs=pd.DataFrame(result)\n","result_gs.columns =[\"Lambda\",\"Mu\", \"Test Accuracy\", \"Number of sensors selected\",\"Selected sensors\"]\n","result_gs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":239},"id":"JBBjSmbRoTOM","executionInfo":{"status":"error","timestamp":1675611048177,"user_tz":-330,"elapsed":1738,"user":{"displayName":"Aytijhya Saha","userId":"15087240692289809888"}},"outputId":"b219c829-8af1-4491-e673-9364086b0ed9"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e9382d1c0765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_modified3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdep_cor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxvals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myvals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'func_modified3' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CPxmWb-bjydI","outputId":"ed272fd1-262d-49c4-ea92-932c0a82856e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/10] END .............hidden_layer_sizes=1;, score=0.303 total time=   7.5s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/10] END .............hidden_layer_sizes=1;, score=0.461 total time=   1.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/10] END .............hidden_layer_sizes=1;, score=0.158 total time=   0.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"name":"stdout","output_type":"stream","text":["[CV 4/10] END .............hidden_layer_sizes=1;, score=0.000 total time=   1.6s\n"]}],"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","# Define the parameter grid for the number of nodes in the hidden layer\n","param_grid = {'hidden_layer_sizes': np.arange(1, 20, 2)}\n","\n","# Create a MLPClassifier object\n","mlp = MLPClassifier(max_iter=1000)\n","\n","# Create a GridSearchCV object\n","grid_search = GridSearchCV(mlp, param_grid, cv=10, scoring='accuracy',verbose = 3)\n","\n","# Fit the GridSearchCV object to the data\n","grid_search.fit(xvals, yvals)\n","\n","# Print the best number of nodes in the hidden layer\n","print(\"Best number of nodes in hidden layer: \", grid_search.best_params_)\n","from itertools import repeat\n","for i in \n","\n","func_modified2(0.5,0.1,grid_search.best_params_['hidden_layer_sizes'],400,10,3,[2,2],dep_cor,xvals,yvals,True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":663,"status":"ok","timestamp":1674896012252,"user":{"displayName":"Aytijhya Saha","userId":"15087240692289809888"},"user_tz":-330},"id":"KavHHMgnlGAh","outputId":"1a0b274f-3793-4644-d49d-eac7ba3a99b1"},"outputs":[{"data":{"text/plain":["array([ 2,  4,  6,  8, 10, 12, 14, 16, 18])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["np.arange(2, 20, 2)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNxCR3OrtbsZjr7zUw9oMHv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}